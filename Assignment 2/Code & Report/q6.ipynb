{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2_q6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ln1YVFB11bI",
        "colab_type": "text"
      },
      "source": [
        "#**Question 6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vfJ0KzO2Dok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import statistics\n",
        "import string\n",
        "import math\n",
        "import os\n",
        "from scipy.spatial import distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKdLlkSL4fk1",
        "colab_type": "text"
      },
      "source": [
        "**Import all file through glob**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4lD7G2Y2LxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file=glob.glob('/content/drive/My Drive/Datasets/Question-6/dataset/*.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXGd8Ru_4mDV",
        "colab_type": "text"
      },
      "source": [
        "**Extract label from file name**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ9OIQQtvzJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label=[]\n",
        "for i in file:\n",
        "  ii=i.split(\"/content/drive/My Drive/Datasets/Question-6/dataset/\")\n",
        "  ii=ii[1]\n",
        "  ii=ii.split(\".txt\")\n",
        "  ii=ii[0]\n",
        "  ii=ii.split(\"_\")\n",
        "  label.append(int(str(ii[1]).split()[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeqy49Ju4vLS",
        "colab_type": "text"
      },
      "source": [
        "**Data prepossessing through TfidfVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iB4iX-shTdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d80c6ce8-a0bf-4cb0-d25c-41988f21b3ed"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "vectorizer = TfidfVectorizer()\n",
        "c=1\n",
        "list1=[]\n",
        "for i in file:\n",
        "  f=open(i,\"rb\")\n",
        "  k=f.read().decode(errors='replace')\n",
        "  k = k.replace('\\n', ' ')\n",
        "  k = k.strip('\\t')\n",
        "  f.close()\n",
        "  k = k.translate(str.maketrans('', '', string.punctuation))\n",
        "  k = k.lower()\n",
        "  list1.append(k)\n",
        "  c+=1\n",
        "train=np.array(list1)\n",
        "tf_idf_vectorizor = TfidfVectorizer(stop_words = 'english',strip_accents='unicode')\n",
        "tf_idf=tf_idf_vectorizor.fit_transform(train)\n",
        "print(tf_idf.shape)\n",
        "tf_idf_norm = normalize(tf_idf)\n",
        "vec=tf_idf_norm.toarray()\n",
        "X_train=np.asarray(vec,dtype=np.float64)\n",
        "label=np.asarray(label,dtype=np.float64)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1735, 30435)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us03-i-A9Jda",
        "colab_type": "text"
      },
      "source": [
        "# **Random Centroid Initialize** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzgNw4tb84x9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0907672c-616a-4ebf-b305-33488ae40406"
      },
      "source": [
        "k_clusters = 5\n",
        "k_means = np.random.uniform(size=(k_clusters,X_train.shape[1]))\n",
        "for row in range(k_clusters):\n",
        "    k_means[row,:] /= np.linalg.norm(k_means[row,:])\n",
        "k_means.shape\n",
        "np.linalg.norm(k_means,axis=1)\n",
        "mean=k_means.copy()\n",
        "mean=np.asarray(mean,dtype=np.float64)\n",
        "old_mean=np.zeros([X_train.shape[1]])\n",
        "print(mean)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00125086 0.00123563 0.00042361 ... 0.00245043 0.00551353 0.00899769]\n",
            " [0.00263968 0.00614764 0.0050626  ... 0.00484575 0.00628862 0.00257506]\n",
            " [0.00763828 0.0036311  0.00439093 ... 0.00571492 0.00140788 0.00082786]\n",
            " [0.00517997 0.00622296 0.00031951 ... 0.00555873 0.00472818 0.00181504]\n",
            " [0.00284018 0.00821176 0.00141627 ... 0.00774598 0.00158713 0.00257392]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw-Xn68LNPZR",
        "colab_type": "text"
      },
      "source": [
        "## **K-Mean Algo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idjr5pDg3nZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flag=True\n",
        "start = 0\n",
        "end = 30\n",
        "list2=[]\n",
        "list1={}\n",
        "while start < end :\n",
        "  list2=[]\n",
        "  list1=[]\n",
        "  for i in range(5):\n",
        "    list2.append([])\n",
        "    list1.append([])\n",
        "  kk=1\n",
        "  for i in range(X_train.shape[0]):\n",
        "    temp=[]\n",
        "    for j in range(mean.shape[0]):\n",
        "      temp.append(distance.euclidean(X_train[i],mean[j]))\n",
        "    index= temp.index(min(temp))\n",
        "    list2[index].append(X_train[i])\n",
        "    list1[index].append(i)\n",
        "  kk+=1\n",
        "  for p in range(mean.shape[0]):\n",
        "    sum=np.zeros([X_train.shape[1]])\n",
        "    sum=np.asarray(sum,dtype=np.float64)\n",
        "    for ind in list2[p]:\n",
        "      sum=sum+ind\n",
        "    mean[p]=sum/len(list2[p])\n",
        "  start+=1\n",
        "  if(flag):\n",
        "    flag = False\n",
        "  else:\n",
        "    count=0\n",
        "    for i in range(5):\n",
        "      if(np.sum(mean[i])==old_mean[i]):\n",
        "        count+=1\n",
        "      old_mean[i]=np.sum(mean[i])\n",
        "    if(count==5):\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRV1uL726Mvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l=np.zeros([X_train.shape[0]])\n",
        "for i in range(len(list1)):\n",
        "  for j in list1[i]:\n",
        "    l[j]=i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G74_SzuaNW2l",
        "colab_type": "text"
      },
      "source": [
        "**Finding homogeneity_score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgvFXBXX5Qek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f34b55c-d41d-4f12-8d17-77491bdb3700"
      },
      "source": [
        "from sklearn.metrics.cluster import homogeneity_score\n",
        "homogeneity_score(label,l)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7817833303645714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}