{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_q2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUxywUv_GLaK",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmyCIj5NFeZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import random\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byk_KeMwDTHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flattern(data):\n",
        "  data_f=[]\n",
        "  for i in range(data.shape[0]):\n",
        "    data_f.append(data[i].flatten())\n",
        "  return np.array(data_f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEXyhWPpGkJ-",
        "colab_type": "text"
      },
      "source": [
        "## **PCA from Q1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpe_8_QW9Aew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class PCA_:\n",
        "    def __init__(self,C=100):\n",
        "        self.C=C\n",
        "    def transform(self,data):\n",
        "        cov=np.cov(data.T)\n",
        "        eig_val, eig_vec= np.linalg.eig(cov)\n",
        "        idx = eig_val.argsort()[::-1]   \n",
        "        eig_val = eig_val[idx]\n",
        "        eig_vec = eig_vec[:,idx]\n",
        "        m= np.real(eig_vec[:,0:self.C])\n",
        "        XX=np.dot(data,m)\n",
        "        return XX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwTzc_yaGs_W",
        "colab_type": "text"
      },
      "source": [
        "## **Load data and apply PCA with 100 component and add Bias**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4fosu6UEoJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46cf4321-0fbe-4255-e463-3fd909fd60d9"
      },
      "source": [
        "data=[]\n",
        "label=[]\n",
        "dim=(100,100)\n",
        "file_path='/content/drive/My Drive/A3/dataset'\n",
        "for _, _, files in os.walk(file_path):\n",
        "  for ii in files:\n",
        "    img=cv2.imread(file_path+\"/\"+ii,cv2.IMREAD_GRAYSCALE)\n",
        "    resized = cv2.resize(img,dim, interpolation = cv2.INTER_AREA)\n",
        "    data.append(resized)\n",
        "    l=ii.split(\"_\")\n",
        "    label.append((l[0]))\n",
        "data=np.array(data)\n",
        "label=np.array(label)\n",
        "data=flattern(data)\n",
        "data=PCA_(100).transform(data)\n",
        "one=np.ones(data.shape[0])\n",
        "data=preprocessing.scale(data)\n",
        "one=one.reshape([data.shape[0],1])\n",
        "data=np.append(data,one,axis=1)\n",
        "print(data.shape)\n",
        "scaler = MinMaxScaler()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(520, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx8hoF7eHO69",
        "colab_type": "text"
      },
      "source": [
        "## **Sigmoid and Cost function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbJNmFAxicbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(Z):\n",
        "  scaler.fit(Z)\n",
        "  Z=scaler.transform(Z)\n",
        "  return 1/(1+np.exp(-Z))\n",
        "def loss(h,y):\n",
        "  m=len(y)\n",
        "  cost = 1 / m * np.sum(-y * np.log(h) - (1 - y) * np.log(1 - h))\n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXbKy42wHX2T",
        "colab_type": "text"
      },
      "source": [
        "## **Split data into train and test (80% 20%)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CfxoNp6jn3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test,Y_train,Y_test = train_test_split(data,label,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW7MfAKQHqFT",
        "colab_type": "text"
      },
      "source": [
        "## **Gradient Descent function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONFgVXdwmst8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad(theta,pre,label,X,al):\n",
        "  alpha=al\n",
        "  error=(pre-label)\n",
        "  theta=theta - alpha * (np.dot((X.T),error)/label.shape[0])\n",
        "  return theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVetV57XHy9P",
        "colab_type": "text"
      },
      "source": [
        "##**Logistic Regression(one vs all)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXNlOaw3kciJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "08a95821-8ef6-455d-9a65-1866a441f7d4"
      },
      "source": [
        "classes=np.unique(Y_train)\n",
        "d={}\n",
        "for cl in classes:\n",
        "  k=True\n",
        "  #theta=np.random.rand(X_train.shape[1],1)\n",
        "  theta=np.zeros([X_train.shape[1],1])\n",
        "  #theta=np.ones([X_train.shape[1],1])\n",
        "  Z = np.dot(X_train,theta)\n",
        "  value=sigmoid(Z)\n",
        "  ty=[]\n",
        "  new_theta=0\n",
        "  for i in Y_train:\n",
        "    if i ==cl:\n",
        "      ty.append(1)\n",
        "    else:\n",
        "      ty.append(0)\n",
        "  ty=np.array(ty)\n",
        "  ty=ty.reshape([len(Y_train),1])\n",
        "  for i in range(5000):\n",
        "    theta=grad(theta,value,ty,X_train,0.1)\n",
        "    Z = np.dot(X_train,theta)\n",
        "    value=sigmoid(Z)\n",
        "    if k:\n",
        "      cost=loss(value,ty)\n",
        "      new_theta=theta.copy()\n",
        "      k=False\n",
        "    else:\n",
        "      new=loss(value,ty)\n",
        "      if(new > cost):\n",
        "        break\n",
        "      new_theta=theta.copy()\n",
        "      # print(\"Cost = \" + str(cost))\n",
        "      cost=new\n",
        "  d[cl]=new_theta\n",
        "  print(str(cl) + \" class done\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "000 class done\n",
            "001 class done\n",
            "002 class done\n",
            "003 class done\n",
            "004 class done\n",
            "005 class done\n",
            "006 class done\n",
            "007 class done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVL-GsdkIF_H",
        "colab_type": "text"
      },
      "source": [
        "## **Classification report and Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcxYnv9cwhdL",
        "colab_type": "code",
        "outputId": "228a6b8f-b0ad-4ebd-fd6b-9913ddf46aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "pre=[]\n",
        "index=list(d.keys())\n",
        "for i in X_test:\n",
        "  v=[]\n",
        "  for j in d.values():\n",
        "    v.append(np.dot(i.T,j))\n",
        "  pre.append(index[v.index(max(v))])\n",
        "pre=np.array(pre)\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre))\n",
        "\n",
        "print(classification_report(Y_test,pre,labels=np.unique(Y_test)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.6442307692307693\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         000       0.50      0.64      0.56        11\n",
            "         001       0.80      0.53      0.64        15\n",
            "         002       0.54      0.70      0.61        10\n",
            "         003       0.67      0.57      0.62        14\n",
            "         004       0.53      0.80      0.64        10\n",
            "         005       0.91      0.77      0.83        13\n",
            "         006       0.55      0.40      0.46        15\n",
            "         007       0.72      0.81      0.76        16\n",
            "\n",
            "    accuracy                           0.64       104\n",
            "   macro avg       0.65      0.65      0.64       104\n",
            "weighted avg       0.66      0.64      0.64       104\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 7  0  1  1  0  0  0  2]\n",
            " [ 4  8  2  0  0  0  1  0]\n",
            " [ 0  0  7  0  0  0  3  0]\n",
            " [ 0  0  0  8  2  1  0  3]\n",
            " [ 0  0  1  0  8  0  1  0]\n",
            " [ 1  1  0  1  0 10  0  0]\n",
            " [ 2  1  1  0  5  0  6  0]\n",
            " [ 0  0  1  2  0  0  0 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}