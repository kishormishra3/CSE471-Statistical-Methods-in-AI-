{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_q3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHqBGS8wMkjh",
        "colab_type": "text"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lArO0snN3Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Flatten\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "import warnings\n",
        "from tensorflow.python.keras.layers import Input\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhtFXt34gD24",
        "colab_type": "text"
      },
      "source": [
        "## **Load data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLVbBwm4AGPD",
        "colab_type": "code",
        "outputId": "de5fa13e-67fd-4940-8284-bed14fcd1026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install python-mnist\n",
        "from mnist import MNIST\n",
        "mndata = MNIST('/content/drive/My Drive/dataset')\n",
        "X_train,Y_train = mndata.load_training()\n",
        "X_test,Y_test= mndata.load_testing()\n",
        "X_train=np.array(X_train)\n",
        "Y_train=np.array(Y_train)\n",
        "X_test=np.array(X_test)\n",
        "Y_test=np.array(Y_test)\n",
        "X_train = X_train.reshape(60000,28,28)\n",
        "X_test = X_test.reshape(10000,28,28)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-mnist in /usr/local/lib/python3.6/dist-packages (0.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcp2HHzdAzzO",
        "colab_type": "code",
        "outputId": "081eb679-1159-4cc0-ffe6-3c2e1cd225d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72d-D8nXgNvV",
        "colab_type": "text"
      },
      "source": [
        "## **Covert label to one hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LudaO8OkC0Ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train_en = to_categorical(Y_train, 10)\n",
        "Y_test_en = to_categorical(Y_test, 10)\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-NhHSYRE0OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flattern(data):\n",
        "  data_f=[]\n",
        "  for i in range(data.shape[0]):\n",
        "    data_f.append(data[i].flatten())\n",
        "  return np.array(data_f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nb1s-sBFX-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_fl=flattern(X_train)\n",
        "X_test_fl=flattern(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9omcz0lwgWfh",
        "colab_type": "text"
      },
      "source": [
        "## **MLP with 1 hidden(1000) layer, Optimizer = rmsprop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C5F3frfPpaX",
        "colab_type": "code",
        "outputId": "033ea10b-22a0-4f82-c2a5-1e2807a694dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(1000, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = X_train_fl.shape[1]))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_fl,Y_train_en, epochs=100, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0167 - accuracy: 0.8889\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0093 - accuracy: 0.9392\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0078 - accuracy: 0.9489\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0071 - accuracy: 0.9535\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0064 - accuracy: 0.9586\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0060 - accuracy: 0.9616\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9639\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9650\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9665\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9681\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9701\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9690\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9704\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9720\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9733\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9735\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9746\n",
            "Epoch 18/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9743\n",
            "Epoch 19/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9747\n",
            "Epoch 20/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0038 - accuracy: 0.9754\n",
            "Epoch 21/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0038 - accuracy: 0.9756\n",
            "Epoch 22/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9761\n",
            "Epoch 23/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9762\n",
            "Epoch 24/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9766\n",
            "Epoch 25/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9761\n",
            "Epoch 26/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9777\n",
            "Epoch 27/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9780\n",
            "Epoch 28/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9782\n",
            "Epoch 29/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9773\n",
            "Epoch 30/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9782\n",
            "Epoch 31/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9790\n",
            "Epoch 32/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9795\n",
            "Epoch 33/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9797\n",
            "Epoch 34/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9795\n",
            "Epoch 35/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9798\n",
            "Epoch 36/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9797\n",
            "Epoch 37/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9800\n",
            "Epoch 38/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0029 - accuracy: 0.9816\n",
            "Epoch 39/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0029 - accuracy: 0.9813\n",
            "Epoch 40/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0029 - accuracy: 0.9810\n",
            "Epoch 41/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9821\n",
            "Epoch 42/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9824\n",
            "Epoch 43/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9824\n",
            "Epoch 44/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9827\n",
            "Epoch 45/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9838\n",
            "Epoch 46/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9837\n",
            "Epoch 47/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9830\n",
            "Epoch 48/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9831\n",
            "Epoch 49/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9838\n",
            "Epoch 50/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9829\n",
            "Epoch 51/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9833\n",
            "Epoch 52/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9842\n",
            "Epoch 53/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9839\n",
            "Epoch 54/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9829\n",
            "Epoch 55/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9826\n",
            "Epoch 56/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9828\n",
            "Epoch 57/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9838\n",
            "Epoch 58/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9827\n",
            "Epoch 59/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9838\n",
            "Epoch 60/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9837\n",
            "Epoch 61/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0024 - accuracy: 0.9848\n",
            "Epoch 62/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0023 - accuracy: 0.9854\n",
            "Epoch 63/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0024 - accuracy: 0.9843\n",
            "Epoch 64/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0023 - accuracy: 0.9855\n",
            "Epoch 65/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0023 - accuracy: 0.9858\n",
            "Epoch 66/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0023 - accuracy: 0.9853\n",
            "Epoch 67/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9867\n",
            "Epoch 68/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0022 - accuracy: 0.9861\n",
            "Epoch 69/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9864\n",
            "Epoch 70/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9867\n",
            "Epoch 71/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9866\n",
            "Epoch 72/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9864\n",
            "Epoch 73/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9865\n",
            "Epoch 74/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9865\n",
            "Epoch 75/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9880\n",
            "Epoch 76/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9874\n",
            "Epoch 77/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9869\n",
            "Epoch 78/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9871\n",
            "Epoch 79/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9872\n",
            "Epoch 80/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 0.9882\n",
            "Epoch 81/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9870\n",
            "Epoch 82/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9872\n",
            "Epoch 83/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 0.9878\n",
            "Epoch 84/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.9887\n",
            "Epoch 85/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 0.9877\n",
            "Epoch 86/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 0.9878\n",
            "Epoch 87/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.9881\n",
            "Epoch 88/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 0.9879\n",
            "Epoch 89/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 0.9873\n",
            "Epoch 90/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 0.9877\n",
            "Epoch 91/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.9885\n",
            "Epoch 92/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.9887\n",
            "Epoch 93/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9891\n",
            "Epoch 94/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.9886\n",
            "Epoch 95/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9891\n",
            "Epoch 96/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9893\n",
            "Epoch 97/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9891\n",
            "Epoch 98/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9890\n",
            "Epoch 99/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0016 - accuracy: 0.9894\n",
            "Epoch 100/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0016 - accuracy: 0.9894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f53b02af2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR7oE9QngqUh",
        "colab_type": "text"
      },
      "source": [
        "## **Accuracy and Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVE6Kt2wPvby",
        "colab_type": "code",
        "outputId": "151f602e-8895-4b7b-c1b8-c6da2a7f5e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "pre = model.predict(X_test_fl)\n",
        "pre_=[]\n",
        "for i in pre:\n",
        "  pre_.append(np.argmax(i))\n",
        "pre_=np.array(pre_)\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre_))\n",
        "\n",
        "print(classification_report(Y_test,pre_,labels=np.unique(Y_test)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.9774\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.98      0.98      0.98      1032\n",
            "           3       0.97      0.98      0.97      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.98      0.96      0.97       892\n",
            "           6       0.97      0.99      0.98       958\n",
            "           7       0.97      0.98      0.97      1028\n",
            "           8       0.97      0.97      0.97       974\n",
            "           9       0.98      0.97      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 960    1    1    1    0    4    7    2    4    0]\n",
            " [   0 1123    1    2    0    0    3    0    6    0]\n",
            " [   1    1 1010    4    1    1    2    7    5    0]\n",
            " [   0    0    4  993    0    2    0    4    6    1]\n",
            " [   2    0    2    0  959    0    4    5    0   10]\n",
            " [   3    0    0   12    1  856   10    1    7    2]\n",
            " [   3    2    0    1    2    2  946    0    1    1]\n",
            " [   0    4    6    4    0    1    0 1007    3    3]\n",
            " [   1    1    3    6    4    1    6    4  943    5]\n",
            " [   0    3    2    5    7    4    1    8    2  977]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfuv892-g0mt",
        "colab_type": "text"
      },
      "source": [
        "## **MLP with 2 hidden layer(1000,1000) Optimizer= rmsprop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vbpe-iCHEDH",
        "colab_type": "code",
        "outputId": "5f28ebe9-4b1b-467e-cd47-417f5c63462a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(1000, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = X_train_fl.shape[1]))\n",
        "\n",
        "model.add(Dense(1000, activation = 'sigmoid'))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_fl,Y_train_en, epochs=100, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0316 - accuracy: 0.7784\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0089 - accuracy: 0.9410\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0075 - accuracy: 0.9517\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0066 - accuracy: 0.9573\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9618\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9647\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9671\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9691\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9709\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9726\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9738\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9761\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9777\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9781\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9791\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9797\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9801\n",
            "Epoch 18/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9801\n",
            "Epoch 19/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0029 - accuracy: 0.9816\n",
            "Epoch 20/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9821\n",
            "Epoch 21/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9821\n",
            "Epoch 22/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9826\n",
            "Epoch 23/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9844\n",
            "Epoch 24/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0024 - accuracy: 0.9848\n",
            "Epoch 25/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0024 - accuracy: 0.9845\n",
            "Epoch 26/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0023 - accuracy: 0.9852\n",
            "Epoch 27/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0022 - accuracy: 0.9859\n",
            "Epoch 28/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9862\n",
            "Epoch 29/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9868\n",
            "Epoch 30/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9869\n",
            "Epoch 31/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9870\n",
            "Epoch 32/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9876\n",
            "Epoch 33/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0019 - accuracy: 0.9882\n",
            "Epoch 34/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.9884\n",
            "Epoch 35/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.9886\n",
            "Epoch 36/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.9884\n",
            "Epoch 37/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9894\n",
            "Epoch 38/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9893\n",
            "Epoch 39/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0016 - accuracy: 0.9899\n",
            "Epoch 40/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0016 - accuracy: 0.9894\n",
            "Epoch 41/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0015 - accuracy: 0.9908\n",
            "Epoch 42/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0015 - accuracy: 0.9906\n",
            "Epoch 43/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0015 - accuracy: 0.9907\n",
            "Epoch 44/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 0.9911\n",
            "Epoch 45/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 0.9916\n",
            "Epoch 46/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 0.9910\n",
            "Epoch 47/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0013 - accuracy: 0.9915\n",
            "Epoch 48/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 0.9915\n",
            "Epoch 49/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0013 - accuracy: 0.9917\n",
            "Epoch 50/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0013 - accuracy: 0.9915\n",
            "Epoch 51/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0012 - accuracy: 0.9920\n",
            "Epoch 52/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0012 - accuracy: 0.9924\n",
            "Epoch 53/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0012 - accuracy: 0.9920\n",
            "Epoch 54/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 0.9929\n",
            "Epoch 55/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0012 - accuracy: 0.9923\n",
            "Epoch 56/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 0.9931\n",
            "Epoch 57/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 0.9933\n",
            "Epoch 58/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0011 - accuracy: 0.9930\n",
            "Epoch 59/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 9.7154e-04 - accuracy: 0.9940\n",
            "Epoch 60/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0010 - accuracy: 0.9939\n",
            "Epoch 61/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 9.8132e-04 - accuracy: 0.9939\n",
            "Epoch 62/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 9.3529e-04 - accuracy: 0.9943\n",
            "Epoch 63/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 9.2422e-04 - accuracy: 0.9943\n",
            "Epoch 64/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 9.4498e-04 - accuracy: 0.9941\n",
            "Epoch 65/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 8.6960e-04 - accuracy: 0.9945\n",
            "Epoch 66/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 8.6533e-04 - accuracy: 0.9947\n",
            "Epoch 67/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 8.8078e-04 - accuracy: 0.9944\n",
            "Epoch 68/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 8.8695e-04 - accuracy: 0.9946\n",
            "Epoch 69/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 7.8794e-04 - accuracy: 0.9952\n",
            "Epoch 70/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 7.6312e-04 - accuracy: 0.9952\n",
            "Epoch 71/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 8.4798e-04 - accuracy: 0.9948\n",
            "Epoch 72/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 7.6303e-04 - accuracy: 0.9952\n",
            "Epoch 73/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 6.7063e-04 - accuracy: 0.9960\n",
            "Epoch 74/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 7.3350e-04 - accuracy: 0.9955\n",
            "Epoch 75/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 7.3345e-04 - accuracy: 0.9953\n",
            "Epoch 76/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 7.3404e-04 - accuracy: 0.9954\n",
            "Epoch 77/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 6.9042e-04 - accuracy: 0.9958\n",
            "Epoch 78/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 6.8844e-04 - accuracy: 0.9959\n",
            "Epoch 79/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 6.0346e-04 - accuracy: 0.9963\n",
            "Epoch 80/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.7724e-04 - accuracy: 0.9964\n",
            "Epoch 81/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 6.4315e-04 - accuracy: 0.9959\n",
            "Epoch 82/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 6.2528e-04 - accuracy: 0.9961\n",
            "Epoch 83/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.8158e-04 - accuracy: 0.9964\n",
            "Epoch 84/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.8262e-04 - accuracy: 0.9964\n",
            "Epoch 85/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.4422e-04 - accuracy: 0.9967\n",
            "Epoch 86/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.9884e-04 - accuracy: 0.9962\n",
            "Epoch 87/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.4314e-04 - accuracy: 0.9967\n",
            "Epoch 88/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.6268e-04 - accuracy: 0.9964\n",
            "Epoch 89/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.0369e-04 - accuracy: 0.9969\n",
            "Epoch 90/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.2547e-04 - accuracy: 0.9967\n",
            "Epoch 91/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.3598e-04 - accuracy: 0.9968\n",
            "Epoch 92/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.0686e-04 - accuracy: 0.9969\n",
            "Epoch 93/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.5820e-04 - accuracy: 0.9973\n",
            "Epoch 94/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.4953e-04 - accuracy: 0.9973\n",
            "Epoch 95/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.4902e-04 - accuracy: 0.9974\n",
            "Epoch 96/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.5148e-04 - accuracy: 0.9973\n",
            "Epoch 97/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.1095e-04 - accuracy: 0.9975\n",
            "Epoch 98/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.0721e-04 - accuracy: 0.9977\n",
            "Epoch 99/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.5219e-04 - accuracy: 0.9971\n",
            "Epoch 100/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 3.8057e-04 - accuracy: 0.9977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f53943184a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N3HE-1EhCAM",
        "colab_type": "text"
      },
      "source": [
        "## **Accuracy and Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM19rkrtvAvn",
        "colab_type": "code",
        "outputId": "a8c9244b-bbbc-4ffb-fa9f-7fb364c86007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "pre = model.predict(X_test_fl)\n",
        "pre_=[]\n",
        "for i in pre:\n",
        "  pre_.append(np.argmax(i))\n",
        "pre_=np.array(pre_)\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre_))\n",
        "\n",
        "print(classification_report(Y_test,pre_,labels=np.unique(Y_test)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.9809\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.98      0.98      0.98      1032\n",
            "           3       0.99      0.98      0.98      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.98      0.97      0.98       892\n",
            "           6       0.97      0.99      0.98       958\n",
            "           7       0.98      0.98      0.98      1028\n",
            "           8       0.98      0.96      0.97       974\n",
            "           9       0.97      0.98      0.98      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 965    0    2    0    0    0    9    1    1    2]\n",
            " [   0 1128    1    0    0    3    2    1    0    0]\n",
            " [   2    0 1011    0    4    0    4    8    3    0]\n",
            " [   0    0    6  986    0    4    0    4    5    5]\n",
            " [   0    2    2    0  964    0    3    2    0    9]\n",
            " [   2    0    0    7    0  869    5    1    4    4]\n",
            " [   2    2    0    1    2    2  948    0    0    1]\n",
            " [   0    3    9    1    0    0    0 1011    0    4]\n",
            " [   3    2    3    4    4    5    7    3  939    4]\n",
            " [   1    5    0    2    5    1    1    4    2  988]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7sqCkO8hEO6",
        "colab_type": "text"
      },
      "source": [
        "## **MLP with 2 hidden layer(1000,1000) Optimizer=SGD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMBOUX4ERLxI",
        "colab_type": "code",
        "outputId": "e6d042ac-acc1-4d6d-a03c-d5cd6f585dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(1000, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = X_train_fl.shape[1]))\n",
        "\n",
        "model.add(Dense(1000, activation = 'sigmoid'))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_fl,Y_train_en, epochs=100, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.1884\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.2675\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0823 - accuracy: 0.3645\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0786 - accuracy: 0.4411\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.4906\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0710 - accuracy: 0.5319\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0673 - accuracy: 0.5741\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.6205\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.6676\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.7021\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0539 - accuracy: 0.7273\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0509 - accuracy: 0.7474\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0482 - accuracy: 0.7604\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.7729\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0431 - accuracy: 0.7885\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.8025\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0388 - accuracy: 0.8166\n",
            "Epoch 18/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0369 - accuracy: 0.8294\n",
            "Epoch 19/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0351 - accuracy: 0.8402\n",
            "Epoch 20/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0335 - accuracy: 0.8487\n",
            "Epoch 21/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0320 - accuracy: 0.8557\n",
            "Epoch 22/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.8605\n",
            "Epoch 23/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.8651\n",
            "Epoch 24/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.8688\n",
            "Epoch 25/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.8724\n",
            "Epoch 26/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.8755\n",
            "Epoch 27/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.8780\n",
            "Epoch 28/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.8806\n",
            "Epoch 29/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.8829\n",
            "Epoch 30/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0233 - accuracy: 0.8855\n",
            "Epoch 31/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.8873\n",
            "Epoch 32/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.8895\n",
            "Epoch 33/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.8914\n",
            "Epoch 34/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0211 - accuracy: 0.8925\n",
            "Epoch 35/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.8946\n",
            "Epoch 36/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.8961\n",
            "Epoch 37/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0198 - accuracy: 0.8971\n",
            "Epoch 38/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.8985\n",
            "Epoch 39/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.8997\n",
            "Epoch 40/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0187 - accuracy: 0.9010\n",
            "Epoch 41/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9023\n",
            "Epoch 42/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.9033\n",
            "Epoch 43/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0178 - accuracy: 0.9046\n",
            "Epoch 44/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0175 - accuracy: 0.9058\n",
            "Epoch 45/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0173 - accuracy: 0.9068\n",
            "Epoch 46/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0170 - accuracy: 0.9076\n",
            "Epoch 47/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9084\n",
            "Epoch 48/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0166 - accuracy: 0.9096\n",
            "Epoch 49/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0164 - accuracy: 0.9106\n",
            "Epoch 50/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0162 - accuracy: 0.9117\n",
            "Epoch 51/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0160 - accuracy: 0.9125\n",
            "Epoch 52/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0158 - accuracy: 0.9133\n",
            "Epoch 53/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9144\n",
            "Epoch 54/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0154 - accuracy: 0.9148\n",
            "Epoch 55/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0152 - accuracy: 0.9159\n",
            "Epoch 56/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0151 - accuracy: 0.9167\n",
            "Epoch 57/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0149 - accuracy: 0.9175\n",
            "Epoch 58/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0148 - accuracy: 0.9179\n",
            "Epoch 59/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0146 - accuracy: 0.9186\n",
            "Epoch 60/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0145 - accuracy: 0.9190\n",
            "Epoch 61/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0143 - accuracy: 0.9200\n",
            "Epoch 62/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0142 - accuracy: 0.9206\n",
            "Epoch 63/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0141 - accuracy: 0.9213\n",
            "Epoch 64/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0140 - accuracy: 0.9217\n",
            "Epoch 65/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0138 - accuracy: 0.9223\n",
            "Epoch 66/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0137 - accuracy: 0.9228\n",
            "Epoch 67/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0136 - accuracy: 0.9236\n",
            "Epoch 68/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0135 - accuracy: 0.9242\n",
            "Epoch 69/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0134 - accuracy: 0.9245\n",
            "Epoch 70/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0133 - accuracy: 0.9251\n",
            "Epoch 71/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0132 - accuracy: 0.9256\n",
            "Epoch 72/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0131 - accuracy: 0.9259\n",
            "Epoch 73/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0130 - accuracy: 0.9266\n",
            "Epoch 74/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0129 - accuracy: 0.9270\n",
            "Epoch 75/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0128 - accuracy: 0.9273\n",
            "Epoch 76/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0127 - accuracy: 0.9277\n",
            "Epoch 77/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0126 - accuracy: 0.9283\n",
            "Epoch 78/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0125 - accuracy: 0.9287\n",
            "Epoch 79/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0124 - accuracy: 0.9291\n",
            "Epoch 80/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0123 - accuracy: 0.9298\n",
            "Epoch 81/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0122 - accuracy: 0.9301\n",
            "Epoch 82/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0122 - accuracy: 0.9308\n",
            "Epoch 83/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0121 - accuracy: 0.9312\n",
            "Epoch 84/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9314\n",
            "Epoch 85/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0119 - accuracy: 0.9317\n",
            "Epoch 86/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0119 - accuracy: 0.9322\n",
            "Epoch 87/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0118 - accuracy: 0.9326\n",
            "Epoch 88/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0117 - accuracy: 0.9328\n",
            "Epoch 89/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0116 - accuracy: 0.9334\n",
            "Epoch 90/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0116 - accuracy: 0.9339\n",
            "Epoch 91/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0115 - accuracy: 0.9344\n",
            "Epoch 92/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9347\n",
            "Epoch 93/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9350\n",
            "Epoch 94/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0113 - accuracy: 0.9354\n",
            "Epoch 95/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0112 - accuracy: 0.9356\n",
            "Epoch 96/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0112 - accuracy: 0.9362\n",
            "Epoch 97/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9366\n",
            "Epoch 98/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0110 - accuracy: 0.9367\n",
            "Epoch 99/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0110 - accuracy: 0.9371\n",
            "Epoch 100/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f53941a7940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X84FocC4hN37",
        "colab_type": "text"
      },
      "source": [
        "## **Accuracy and Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBvtwsM1SG51",
        "colab_type": "code",
        "outputId": "6aea5634-0898-449b-b37b-ec691e39e7d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "pre = model.predict(X_test_fl)\n",
        "pre_=[]\n",
        "for i in pre:\n",
        "  pre_.append(np.argmax(i))\n",
        "pre_=np.array(pre_)\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre_))\n",
        "\n",
        "print(classification_report(Y_test,pre_,labels=np.unique(Y_test)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.9238\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       980\n",
            "           1       0.98      0.98      0.98      1135\n",
            "           2       0.92      0.89      0.90      1032\n",
            "           3       0.91      0.92      0.91      1010\n",
            "           4       0.92      0.94      0.93       982\n",
            "           5       0.90      0.88      0.89       892\n",
            "           6       0.93      0.94      0.94       958\n",
            "           7       0.93      0.91      0.92      1028\n",
            "           8       0.89      0.89      0.89       974\n",
            "           9       0.91      0.90      0.90      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 963    0    3    2    0    5    3    1    3    0]\n",
            " [   0 1111    2    5    1    1    3    1   11    0]\n",
            " [  10    0  923   18   10    2   14   17   29    9]\n",
            " [   3    0   22  926    0   19    3   16   15    6]\n",
            " [   1    1    5    0  922    1   14    2    6   30]\n",
            " [  10    1    7   30   10  784   12    6   24    8]\n",
            " [  16    3    3    1   10   19  902    1    3    0]\n",
            " [   3   12   29    3    9    0    0  937    5   30]\n",
            " [   7    3   10   20   11   23   13   11  864   12]\n",
            " [  10    3    4   10   34   17    1   18    6  906]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAwTcFDUhShS",
        "colab_type": "text"
      },
      "source": [
        "# **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwf2VzTmF4JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers.convolutional import Conv2D\n",
        "from tensorflow.python.keras.layers.pooling import MaxPooling2D\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Flatten\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers  import Dense, Conv2D, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMWakIN6hYJ2",
        "colab_type": "text"
      },
      "source": [
        "## **CNN with 2 Conv(64,32), 2 Pooling(2,2) Optimizer=Adam**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew7hqipYPLg0",
        "colab_type": "code",
        "outputId": "76208e09-fd70-43d5-d977-6ee2440b8387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train_ = X_train.reshape(60000,28,28,1)\n",
        "X_test_ = X_test.reshape(10000,28,28,1)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_,Y_train_en, validation_data=(X_test_, Y_test_en),epochs=100, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.5087 - accuracy: 0.9110 - val_loss: 0.1011 - val_accuracy: 0.9703\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0891 - accuracy: 0.9735 - val_loss: 0.0823 - val_accuracy: 0.9744\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0655 - accuracy: 0.9799 - val_loss: 0.0702 - val_accuracy: 0.9782\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0572 - accuracy: 0.9823 - val_loss: 0.0800 - val_accuracy: 0.9790\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0462 - accuracy: 0.9853 - val_loss: 0.0732 - val_accuracy: 0.9797\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.0958 - val_accuracy: 0.9757\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.0563 - val_accuracy: 0.9840\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.0649 - val_accuracy: 0.9827\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0826 - val_accuracy: 0.9788\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.0895 - val_accuracy: 0.9781\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0653 - val_accuracy: 0.9837\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.0690 - val_accuracy: 0.9829\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0674 - val_accuracy: 0.9847\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0719 - val_accuracy: 0.9833\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0782 - val_accuracy: 0.9833\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.0825 - val_accuracy: 0.9840\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0887 - val_accuracy: 0.9838\n",
            "Epoch 18/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0893 - val_accuracy: 0.9819\n",
            "Epoch 19/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.1102 - val_accuracy: 0.9823\n",
            "Epoch 20/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1025 - val_accuracy: 0.9841\n",
            "Epoch 21/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0996 - val_accuracy: 0.9830\n",
            "Epoch 22/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.1231 - val_accuracy: 0.9806\n",
            "Epoch 23/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.1101 - val_accuracy: 0.9833\n",
            "Epoch 24/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.1196 - val_accuracy: 0.9828\n",
            "Epoch 25/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.1267 - val_accuracy: 0.9835\n",
            "Epoch 26/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.1016 - val_accuracy: 0.9841\n",
            "Epoch 27/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.1132 - val_accuracy: 0.9846\n",
            "Epoch 28/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.1237 - val_accuracy: 0.9851\n",
            "Epoch 29/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.1082 - val_accuracy: 0.9847\n",
            "Epoch 30/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.1169 - val_accuracy: 0.9857\n",
            "Epoch 31/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.1519 - val_accuracy: 0.9832\n",
            "Epoch 32/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.1357 - val_accuracy: 0.9846\n",
            "Epoch 33/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.1616 - val_accuracy: 0.9846\n",
            "Epoch 34/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.1442 - val_accuracy: 0.9853\n",
            "Epoch 35/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.1693 - val_accuracy: 0.9820\n",
            "Epoch 36/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.1434 - val_accuracy: 0.9861\n",
            "Epoch 37/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.1730 - val_accuracy: 0.9837\n",
            "Epoch 38/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.1646 - val_accuracy: 0.9844\n",
            "Epoch 39/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.1871 - val_accuracy: 0.9849\n",
            "Epoch 40/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.1721 - val_accuracy: 0.9857\n",
            "Epoch 41/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.1953 - val_accuracy: 0.9849\n",
            "Epoch 42/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.1695 - val_accuracy: 0.9860\n",
            "Epoch 43/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.2085 - val_accuracy: 0.9838\n",
            "Epoch 44/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.1967 - val_accuracy: 0.9847\n",
            "Epoch 45/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0164 - accuracy: 0.9970 - val_loss: 0.2129 - val_accuracy: 0.9829\n",
            "Epoch 46/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.1686 - val_accuracy: 0.9853\n",
            "Epoch 47/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.1984 - val_accuracy: 0.9852\n",
            "Epoch 48/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.1867 - val_accuracy: 0.9864\n",
            "Epoch 49/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.2421 - val_accuracy: 0.9844\n",
            "Epoch 50/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.2464 - val_accuracy: 0.9844\n",
            "Epoch 51/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 0.2185 - val_accuracy: 0.9850\n",
            "Epoch 52/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.2395 - val_accuracy: 0.9847\n",
            "Epoch 53/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.2591 - val_accuracy: 0.9850\n",
            "Epoch 54/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0180 - accuracy: 0.9976 - val_loss: 0.2492 - val_accuracy: 0.9862\n",
            "Epoch 55/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.2436 - val_accuracy: 0.9851\n",
            "Epoch 56/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0146 - accuracy: 0.9977 - val_loss: 0.3069 - val_accuracy: 0.9823\n",
            "Epoch 57/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.2408 - val_accuracy: 0.9868\n",
            "Epoch 58/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0181 - accuracy: 0.9978 - val_loss: 0.2969 - val_accuracy: 0.9845\n",
            "Epoch 59/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0109 - accuracy: 0.9984 - val_loss: 0.2443 - val_accuracy: 0.9866\n",
            "Epoch 60/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.2606 - val_accuracy: 0.9860\n",
            "Epoch 61/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.3157 - val_accuracy: 0.9855\n",
            "Epoch 62/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0141 - accuracy: 0.9981 - val_loss: 0.2729 - val_accuracy: 0.9873\n",
            "Epoch 63/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.2979 - val_accuracy: 0.9860\n",
            "Epoch 64/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.2429 - val_accuracy: 0.9873\n",
            "Epoch 65/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.2853 - val_accuracy: 0.9862\n",
            "Epoch 66/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.2579 - val_accuracy: 0.9882\n",
            "Epoch 67/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0108 - accuracy: 0.9984 - val_loss: 0.3275 - val_accuracy: 0.9856\n",
            "Epoch 68/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0156 - accuracy: 0.9981 - val_loss: 0.3349 - val_accuracy: 0.9846\n",
            "Epoch 69/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.3205 - val_accuracy: 0.9861\n",
            "Epoch 70/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0128 - accuracy: 0.9985 - val_loss: 0.3355 - val_accuracy: 0.9859\n",
            "Epoch 71/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0155 - accuracy: 0.9980 - val_loss: 0.3556 - val_accuracy: 0.9857\n",
            "Epoch 72/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0168 - accuracy: 0.9982 - val_loss: 0.3779 - val_accuracy: 0.9854\n",
            "Epoch 73/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.3459 - val_accuracy: 0.9854\n",
            "Epoch 74/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0140 - accuracy: 0.9984 - val_loss: 0.3356 - val_accuracy: 0.9870\n",
            "Epoch 75/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0163 - accuracy: 0.9981 - val_loss: 0.3756 - val_accuracy: 0.9863\n",
            "Epoch 76/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.3514 - val_accuracy: 0.9874\n",
            "Epoch 77/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0161 - accuracy: 0.9983 - val_loss: 0.4252 - val_accuracy: 0.9859\n",
            "Epoch 78/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0128 - accuracy: 0.9987 - val_loss: 0.3382 - val_accuracy: 0.9869\n",
            "Epoch 79/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.5943 - val_accuracy: 0.9837\n",
            "Epoch 80/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0169 - accuracy: 0.9983 - val_loss: 0.4019 - val_accuracy: 0.9860\n",
            "Epoch 81/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.4047 - val_accuracy: 0.9866\n",
            "Epoch 82/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0191 - accuracy: 0.9981 - val_loss: 0.4250 - val_accuracy: 0.9849\n",
            "Epoch 83/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0160 - accuracy: 0.9983 - val_loss: 0.4419 - val_accuracy: 0.9857\n",
            "Epoch 84/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0108 - accuracy: 0.9989 - val_loss: 0.4728 - val_accuracy: 0.9839\n",
            "Epoch 85/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0111 - accuracy: 0.9988 - val_loss: 0.4520 - val_accuracy: 0.9860\n",
            "Epoch 86/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0139 - accuracy: 0.9986 - val_loss: 0.4286 - val_accuracy: 0.9861\n",
            "Epoch 87/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0132 - accuracy: 0.9985 - val_loss: 0.4798 - val_accuracy: 0.9864\n",
            "Epoch 88/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0214 - accuracy: 0.9982 - val_loss: 0.4554 - val_accuracy: 0.9862\n",
            "Epoch 89/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.4065 - val_accuracy: 0.9870\n",
            "Epoch 90/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0147 - accuracy: 0.9985 - val_loss: 0.4247 - val_accuracy: 0.9869\n",
            "Epoch 91/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.4426 - val_accuracy: 0.9870\n",
            "Epoch 92/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0110 - accuracy: 0.9990 - val_loss: 0.5220 - val_accuracy: 0.9849\n",
            "Epoch 93/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0149 - accuracy: 0.9986 - val_loss: 0.4932 - val_accuracy: 0.9875\n",
            "Epoch 94/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0144 - accuracy: 0.9988 - val_loss: 0.4606 - val_accuracy: 0.9869\n",
            "Epoch 95/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0161 - accuracy: 0.9986 - val_loss: 0.5860 - val_accuracy: 0.9856\n",
            "Epoch 96/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0163 - accuracy: 0.9987 - val_loss: 0.5153 - val_accuracy: 0.9876\n",
            "Epoch 97/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.4974 - val_accuracy: 0.9875\n",
            "Epoch 98/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0161 - accuracy: 0.9988 - val_loss: 0.6164 - val_accuracy: 0.9875\n",
            "Epoch 99/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0151 - accuracy: 0.9988 - val_loss: 0.6531 - val_accuracy: 0.9849\n",
            "Epoch 100/100\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0140 - accuracy: 0.9990 - val_loss: 0.5828 - val_accuracy: 0.9880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f53940ada20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my9zQhz2hoZD",
        "colab_type": "text"
      },
      "source": [
        "## **Accuracy and Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNqd1PVnGEB5",
        "colab_type": "code",
        "outputId": "f8f21470-d3bf-40e0-b96c-f359ef4ccaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "pre = model.predict(X_test_)\n",
        "pre_=[]\n",
        "for i in pre:\n",
        "  pre_.append(np.argmax(i))\n",
        "pre_=np.array(pre_)\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre_))\n",
        "\n",
        "print(classification_report(Y_test,pre_,labels=np.unique(Y_test)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.988\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.98      0.99      1032\n",
            "           3       0.99      0.99      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       0.97      0.99      0.98       892\n",
            "           6       1.00      0.98      0.99       958\n",
            "           7       0.98      0.99      0.99      1028\n",
            "           8       0.98      0.99      0.99       974\n",
            "           9       0.99      0.98      0.98      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 976    1    0    0    0    1    1    0    1    0]\n",
            " [   0 1126    1    2    0    1    2    1    2    0]\n",
            " [   1    3 1016    3    1    1    0    4    3    0]\n",
            " [   0    0    2  998    0    6    0    2    2    0]\n",
            " [   0    0    1    0  969    0    0    3    1    8]\n",
            " [   1    0    0    4    0  885    1    0    0    1]\n",
            " [   3    2    0    0    6    3  942    0    2    0]\n",
            " [   1    2    4    0    0    0    0 1021    0    0]\n",
            " [   3    0    0    0    2    2    0    2  962    3]\n",
            " [   1    0    0    1    4    9    0    5    4  985]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFbxs_B_hrFr",
        "colab_type": "text"
      },
      "source": [
        "## **CNN with 3 Conv(64,32,32), 3 Pooling(2,2) Optimizer=rmsprop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNPXZc4LUJ2e",
        "colab_type": "code",
        "outputId": "90d15811-fcf8-43a2-b2fa-dad3a4140996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train_ = X_train.reshape(60000,28,28,1)\n",
        "X_test_ = X_test.reshape(10000,28,28,1)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_,Y_train_en, validation_data=(X_test_, Y_test_en),epochs=100, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.6996 - accuracy: 0.8631 - val_loss: 0.1664 - val_accuracy: 0.9521\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1168 - accuracy: 0.9650 - val_loss: 0.0971 - val_accuracy: 0.9700\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0856 - accuracy: 0.9744 - val_loss: 0.0783 - val_accuracy: 0.9783\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0659 - accuracy: 0.9806 - val_loss: 0.0955 - val_accuracy: 0.9746\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0569 - accuracy: 0.9828 - val_loss: 0.0712 - val_accuracy: 0.9815\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0502 - accuracy: 0.9849 - val_loss: 0.0774 - val_accuracy: 0.9817\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0446 - accuracy: 0.9866 - val_loss: 0.0844 - val_accuracy: 0.9774\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0412 - accuracy: 0.9872 - val_loss: 0.0923 - val_accuracy: 0.9782\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0380 - accuracy: 0.9886 - val_loss: 0.0799 - val_accuracy: 0.9814\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0711 - val_accuracy: 0.9842\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.1131 - val_accuracy: 0.9758\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.1024 - val_accuracy: 0.9812\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.0922 - val_accuracy: 0.9824\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 0.1204 - val_accuracy: 0.9787\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.1448 - val_accuracy: 0.9752\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0259 - accuracy: 0.9931 - val_loss: 0.1008 - val_accuracy: 0.9826\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.1308 - val_accuracy: 0.9817\n",
            "Epoch 18/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0245 - accuracy: 0.9935 - val_loss: 0.1170 - val_accuracy: 0.9833\n",
            "Epoch 19/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.1311 - val_accuracy: 0.9822\n",
            "Epoch 20/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.1407 - val_accuracy: 0.9815\n",
            "Epoch 21/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.1509 - val_accuracy: 0.9827\n",
            "Epoch 22/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.1390 - val_accuracy: 0.9830\n",
            "Epoch 23/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.1531 - val_accuracy: 0.9823\n",
            "Epoch 24/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.1487 - val_accuracy: 0.9815\n",
            "Epoch 25/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.1442 - val_accuracy: 0.9833\n",
            "Epoch 26/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.1804 - val_accuracy: 0.9802\n",
            "Epoch 27/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0185 - accuracy: 0.9959 - val_loss: 0.1406 - val_accuracy: 0.9850\n",
            "Epoch 28/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0228 - accuracy: 0.9952 - val_loss: 0.1565 - val_accuracy: 0.9829\n",
            "Epoch 29/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.1631 - val_accuracy: 0.9847\n",
            "Epoch 30/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 0.1845 - val_accuracy: 0.9833\n",
            "Epoch 31/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.1746 - val_accuracy: 0.9843\n",
            "Epoch 32/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.1878 - val_accuracy: 0.9835\n",
            "Epoch 33/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0206 - accuracy: 0.9961 - val_loss: 0.1900 - val_accuracy: 0.9832\n",
            "Epoch 34/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0207 - accuracy: 0.9963 - val_loss: 0.1906 - val_accuracy: 0.9845\n",
            "Epoch 35/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0175 - accuracy: 0.9966 - val_loss: 0.2160 - val_accuracy: 0.9825\n",
            "Epoch 36/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 0.2234 - val_accuracy: 0.9833\n",
            "Epoch 37/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0184 - accuracy: 0.9966 - val_loss: 0.2159 - val_accuracy: 0.9841\n",
            "Epoch 38/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0195 - accuracy: 0.9967 - val_loss: 0.2852 - val_accuracy: 0.9795\n",
            "Epoch 39/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0245 - accuracy: 0.9962 - val_loss: 0.2554 - val_accuracy: 0.9834\n",
            "Epoch 40/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0216 - accuracy: 0.9962 - val_loss: 0.2375 - val_accuracy: 0.9841\n",
            "Epoch 41/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0218 - accuracy: 0.9964 - val_loss: 0.2476 - val_accuracy: 0.9835\n",
            "Epoch 42/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0182 - accuracy: 0.9969 - val_loss: 0.2553 - val_accuracy: 0.9849\n",
            "Epoch 43/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0210 - accuracy: 0.9967 - val_loss: 0.2903 - val_accuracy: 0.9810\n",
            "Epoch 44/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.2355 - val_accuracy: 0.9861\n",
            "Epoch 45/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0206 - accuracy: 0.9971 - val_loss: 0.2890 - val_accuracy: 0.9835\n",
            "Epoch 46/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 0.3073 - val_accuracy: 0.9826\n",
            "Epoch 47/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0227 - accuracy: 0.9969 - val_loss: 0.3358 - val_accuracy: 0.9807\n",
            "Epoch 48/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.3097 - val_accuracy: 0.9815\n",
            "Epoch 49/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0173 - accuracy: 0.9971 - val_loss: 0.2832 - val_accuracy: 0.9840\n",
            "Epoch 50/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0197 - accuracy: 0.9973 - val_loss: 0.2923 - val_accuracy: 0.9838\n",
            "Epoch 51/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0216 - accuracy: 0.9969 - val_loss: 0.3447 - val_accuracy: 0.9807\n",
            "Epoch 52/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0212 - accuracy: 0.9970 - val_loss: 0.3371 - val_accuracy: 0.9838\n",
            "Epoch 53/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0183 - accuracy: 0.9972 - val_loss: 0.3252 - val_accuracy: 0.9825\n",
            "Epoch 54/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0189 - accuracy: 0.9971 - val_loss: 0.3560 - val_accuracy: 0.9827\n",
            "Epoch 55/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0212 - accuracy: 0.9973 - val_loss: 0.3320 - val_accuracy: 0.9836\n",
            "Epoch 56/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0189 - accuracy: 0.9976 - val_loss: 0.3564 - val_accuracy: 0.9831\n",
            "Epoch 57/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0195 - accuracy: 0.9973 - val_loss: 0.3456 - val_accuracy: 0.9841\n",
            "Epoch 58/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0201 - accuracy: 0.9973 - val_loss: 0.3985 - val_accuracy: 0.9837\n",
            "Epoch 59/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0255 - accuracy: 0.9972 - val_loss: 0.4144 - val_accuracy: 0.9826\n",
            "Epoch 60/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0203 - accuracy: 0.9974 - val_loss: 0.4472 - val_accuracy: 0.9816\n",
            "Epoch 61/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0211 - accuracy: 0.9975 - val_loss: 0.4546 - val_accuracy: 0.9836\n",
            "Epoch 62/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0248 - accuracy: 0.9975 - val_loss: 0.4786 - val_accuracy: 0.9828\n",
            "Epoch 63/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0239 - accuracy: 0.9975 - val_loss: 0.4632 - val_accuracy: 0.9828\n",
            "Epoch 64/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0242 - accuracy: 0.9977 - val_loss: 0.3949 - val_accuracy: 0.9849\n",
            "Epoch 65/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0279 - accuracy: 0.9972 - val_loss: 0.4261 - val_accuracy: 0.9824\n",
            "Epoch 66/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0239 - accuracy: 0.9974 - val_loss: 0.4898 - val_accuracy: 0.9831\n",
            "Epoch 67/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0218 - accuracy: 0.9977 - val_loss: 0.5199 - val_accuracy: 0.9828\n",
            "Epoch 68/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0185 - accuracy: 0.9980 - val_loss: 0.4908 - val_accuracy: 0.9817\n",
            "Epoch 69/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0244 - accuracy: 0.9974 - val_loss: 0.4595 - val_accuracy: 0.9829\n",
            "Epoch 70/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0239 - accuracy: 0.9978 - val_loss: 0.5359 - val_accuracy: 0.9830\n",
            "Epoch 71/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0139 - accuracy: 0.9984 - val_loss: 0.4552 - val_accuracy: 0.9845\n",
            "Epoch 72/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0239 - accuracy: 0.9978 - val_loss: 0.5271 - val_accuracy: 0.9843\n",
            "Epoch 73/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0219 - accuracy: 0.9977 - val_loss: 0.5541 - val_accuracy: 0.9838\n",
            "Epoch 74/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0227 - accuracy: 0.9978 - val_loss: 0.5297 - val_accuracy: 0.9844\n",
            "Epoch 75/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0197 - accuracy: 0.9977 - val_loss: 0.5066 - val_accuracy: 0.9846\n",
            "Epoch 76/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0255 - accuracy: 0.9978 - val_loss: 0.6010 - val_accuracy: 0.9811\n",
            "Epoch 77/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0262 - accuracy: 0.9976 - val_loss: 0.5279 - val_accuracy: 0.9834\n",
            "Epoch 78/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0220 - accuracy: 0.9977 - val_loss: 0.5512 - val_accuracy: 0.9831\n",
            "Epoch 79/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0169 - accuracy: 0.9981 - val_loss: 0.5969 - val_accuracy: 0.9818\n",
            "Epoch 80/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0189 - accuracy: 0.9980 - val_loss: 0.6308 - val_accuracy: 0.9825\n",
            "Epoch 81/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0247 - accuracy: 0.9980 - val_loss: 0.6249 - val_accuracy: 0.9815\n",
            "Epoch 82/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0198 - accuracy: 0.9983 - val_loss: 0.6003 - val_accuracy: 0.9827\n",
            "Epoch 83/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0275 - accuracy: 0.9978 - val_loss: 0.5915 - val_accuracy: 0.9834\n",
            "Epoch 84/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0231 - accuracy: 0.9983 - val_loss: 0.5518 - val_accuracy: 0.9841\n",
            "Epoch 85/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0241 - accuracy: 0.9977 - val_loss: 0.5890 - val_accuracy: 0.9852\n",
            "Epoch 86/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0202 - accuracy: 0.9980 - val_loss: 0.5717 - val_accuracy: 0.9851\n",
            "Epoch 87/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0231 - accuracy: 0.9981 - val_loss: 0.5949 - val_accuracy: 0.9826\n",
            "Epoch 88/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0211 - accuracy: 0.9980 - val_loss: 0.5552 - val_accuracy: 0.9836\n",
            "Epoch 89/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0202 - accuracy: 0.9982 - val_loss: 0.7169 - val_accuracy: 0.9816\n",
            "Epoch 90/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0167 - accuracy: 0.9983 - val_loss: 0.6703 - val_accuracy: 0.9833\n",
            "Epoch 91/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0283 - accuracy: 0.9976 - val_loss: 0.6198 - val_accuracy: 0.9845\n",
            "Epoch 92/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0266 - accuracy: 0.9980 - val_loss: 0.6742 - val_accuracy: 0.9825\n",
            "Epoch 93/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0223 - accuracy: 0.9984 - val_loss: 0.6304 - val_accuracy: 0.9835\n",
            "Epoch 94/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0229 - accuracy: 0.9981 - val_loss: 0.7023 - val_accuracy: 0.9834\n",
            "Epoch 95/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0256 - accuracy: 0.9981 - val_loss: 0.7575 - val_accuracy: 0.9828\n",
            "Epoch 96/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0243 - accuracy: 0.9981 - val_loss: 0.8216 - val_accuracy: 0.9816\n",
            "Epoch 97/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0236 - accuracy: 0.9981 - val_loss: 0.6281 - val_accuracy: 0.9850\n",
            "Epoch 98/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0225 - accuracy: 0.9983 - val_loss: 0.6947 - val_accuracy: 0.9829\n",
            "Epoch 99/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0237 - accuracy: 0.9983 - val_loss: 0.7028 - val_accuracy: 0.9838\n",
            "Epoch 100/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0204 - accuracy: 0.9985 - val_loss: 0.7705 - val_accuracy: 0.9843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f537c3adc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-VHcxYHh5v4",
        "colab_type": "text"
      },
      "source": [
        "## **Accuracy and Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCk5p95oUYRh",
        "colab_type": "code",
        "outputId": "cc043ada-81ff-4e5d-a363-adb823440c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "pre = model.predict(X_test_)\n",
        "pre_=[]\n",
        "for i in pre:\n",
        "  pre_.append(np.argmax(i))\n",
        "pre_=np.array(pre_)\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre_))\n",
        "\n",
        "print(classification_report(Y_test,pre_,labels=np.unique(Y_test)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.9843\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.98      1.00      0.99      1135\n",
            "           2       0.99      0.98      0.98      1032\n",
            "           3       0.99      0.98      0.99      1010\n",
            "           4       0.98      0.99      0.99       982\n",
            "           5       0.99      0.98      0.98       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.97      0.98      0.97      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       0.99      0.97      0.98      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 966    1    0    1    3    0    3    4    0    2]\n",
            " [   0 1133    0    0    0    0    0    1    1    0]\n",
            " [   2    2 1010    2    0    0    1   14    0    1]\n",
            " [   0    2    3  992    0    5    0    7    1    0]\n",
            " [   0    1    0    0  976    0    0    0    1    4]\n",
            " [   4    2    0    5    0  871    5    1    4    0]\n",
            " [   3    3    0    0    3    3  945    0    1    0]\n",
            " [   0    9    9    1    1    0    0 1005    2    1]\n",
            " [   2    2    0    2    2    0    0    0  962    4]\n",
            " [   0    3    0    0   11    2    1    5    4  983]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMU9F5zth73Z",
        "colab_type": "text"
      },
      "source": [
        "## **SVM with different Kernal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSNt6-LZiEw_",
        "colab_type": "text"
      },
      "source": [
        "### **Kernal=rbf**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4hjqMkDJLNU",
        "colab_type": "code",
        "outputId": "76231efe-9e29-48c8-b4d3-a0a8e7f6bee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train_fl, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abn4nmqeLjNf",
        "colab_type": "code",
        "outputId": "6a12f8e0-4942-4c60-8f25-37eb81bd187b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "pre_ = clf.predict(X_test_fl)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre_))\n",
        "\n",
        "print(classification_report(Y_test,pre_,labels=np.unique(Y_test)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.9792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.98      0.97      0.98      1032\n",
            "           3       0.97      0.99      0.98      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.99      0.98      0.98       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.98      0.97      0.97      1028\n",
            "           8       0.97      0.98      0.97       974\n",
            "           9       0.97      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 973    0    1    0    0    2    1    1    2    0]\n",
            " [   0 1126    3    1    0    1    1    1    2    0]\n",
            " [   6    1 1006    2    1    0    2    7    6    1]\n",
            " [   0    0    2  995    0    2    0    5    5    1]\n",
            " [   0    0    5    0  961    0    3    0    2   11]\n",
            " [   2    0    0    9    0  871    4    1    4    1]\n",
            " [   6    2    0    0    2    3  944    0    1    0]\n",
            " [   0    6   11    1    1    0    0  996    2   11]\n",
            " [   3    0    2    6    3    2    2    3  950    3]\n",
            " [   3    4    1    7   10    2    1    7    4  970]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vwujWTxiLx7",
        "colab_type": "text"
      },
      "source": [
        "### **Kernal=Sigmoid**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilNj1G0CLlms",
        "colab_type": "code",
        "outputId": "5fe8f907-dc82-45c0-d77b-e88eab061eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "clf = svm.SVC(kernel='sigmoid')\n",
        "clf.fit(X_train_fl, Y_train)\n",
        "pre_ = clf.predict(X_test_fl)\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre_))\n",
        "\n",
        "print(classification_report(Y_test,pre_,labels=np.unique(Y_test)))\n",
        "\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.7759\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82       980\n",
            "           1       0.88      0.95      0.91      1135\n",
            "           2       0.75      0.75      0.75      1032\n",
            "           3       0.78      0.72      0.75      1010\n",
            "           4       0.78      0.85      0.81       982\n",
            "           5       0.57      0.66      0.61       892\n",
            "           6       0.85      0.82      0.83       958\n",
            "           7       0.88      0.83      0.85      1028\n",
            "           8       0.69      0.64      0.67       974\n",
            "           9       0.76      0.68      0.72      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.77      0.77      0.77     10000\n",
            "weighted avg       0.78      0.78      0.78     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 812    0   29    6    0   92   35    2    4    0]\n",
            " [   0 1073   13   15    0    3    4    1   26    0]\n",
            " [  29   44  779   25   20   15   46    6   60    8]\n",
            " [  29   10   38  725    2  120    6   14   42   24]\n",
            " [   5    5   11    1  830   11   19    4   18   78]\n",
            " [  48   24   12  107   14  591   20    6   59   11]\n",
            " [  17    5   75    2   31   35  784    0    9    0]\n",
            " [  25   15   38   11   17    6    0  850   13   53]\n",
            " [  24   40   31   32   30  128   11    9  624   45]\n",
            " [  18    6   16    8  121   31    0   73   45  691]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbj8HDVXiQe-",
        "colab_type": "text"
      },
      "source": [
        "### **Kernal=Poly**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx7YVEGPWFPb",
        "colab_type": "code",
        "outputId": "f8df3319-5ded-4418-a73f-7e6268358d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X_train_fl, Y_train)\n",
        "pre_ = clf.predict(X_test_fl)\n",
        "print(\"Accuracy : \",accuracy_score(Y_test,pre_))\n",
        "\n",
        "print(classification_report(Y_test,pre_,labels=np.unique(Y_test)))\n",
        "\n",
        "print(\"\\n\\nConfusion_Matrix\")\n",
        "print(confusion_matrix(Y_test,pre_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.9771\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.97      0.99      0.98      1135\n",
            "           2       0.98      0.97      0.98      1032\n",
            "           3       0.98      0.97      0.98      1010\n",
            "           4       0.97      0.98      0.98       982\n",
            "           5       0.97      0.97      0.97       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.97      0.97      0.97      1028\n",
            "           8       0.98      0.97      0.98       974\n",
            "           9       0.97      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "\n",
            "\n",
            "Confusion_Matrix\n",
            "[[ 969    0    2    0    0    4    2    1    2    0]\n",
            " [   0 1127    2    1    0    0    3    0    2    0]\n",
            " [   6    2 1006    0    2    1    3    9    3    0]\n",
            " [   0    2    3  984    0    6    0    6    5    4]\n",
            " [   1    0    3    0  966    0    4    0    0    8]\n",
            " [   2    0    0    8    1  869    4    1    5    2]\n",
            " [   4    4    2    0    3    6  937    0    2    0]\n",
            " [   0   15    8    1    1    0    0  995    0    8]\n",
            " [   1    1    2    5    5    5    0    3  949    3]\n",
            " [   3    6    1    4   14    5    0    6    1  969]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp7uNtLs4Abu",
        "colab_type": "text"
      },
      "source": [
        "## **Submit Format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bSASrkl3oQG",
        "colab_type": "code",
        "outputId": "fef4d357-b3ca-46d0-8a3c-cdcbe9587c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Mar 31 19:35:15 2020\n",
        "\n",
        "@author: kishor\n",
        "\"\"\"\n",
        "!pip install python-mnist\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import sys\n",
        "from mnist import MNIST\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D\n",
        "from tensorflow.python.keras.layers.pooling import MaxPooling2D\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Flatten\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers  import Dense, Conv2D, Flatten\n",
        "from keras.utils import to_categorical\n",
        "if __name__ == \"__main__\":\n",
        "    file_path='/content/drive/My Drive/dataset'\n",
        "    mndata = MNIST(file_path)\n",
        "    X_train,Y_train = mndata.load_training()\n",
        "    X_test,Y_test= mndata.load_testing()\n",
        "    X_train=np.array(X_train)\n",
        "    Y_train=np.array(Y_train)\n",
        "    X_test=np.array(X_test)\n",
        "    Y_train_en = to_categorical(Y_train, 10)\n",
        "    X_train_ = X_train.reshape(60000,28,28,1)\n",
        "    X_test_ = X_test.reshape(10000,28,28,1)\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(X_train_,Y_train_en,epochs=100, batch_size=100,verbose=0)\n",
        "    pre= model.predict(X_test_)\n",
        "    for i in pre:\n",
        "        print(np.argmax(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "9\n",
            "9\n",
            "8\n",
            "4\n",
            "1\n",
            "0\n",
            "6\n",
            "0\n",
            "9\n",
            "6\n",
            "8\n",
            "6\n",
            "1\n",
            "1\n",
            "9\n",
            "8\n",
            "9\n",
            "2\n",
            "3\n",
            "5\n",
            "5\n",
            "9\n",
            "4\n",
            "2\n",
            "1\n",
            "9\n",
            "4\n",
            "3\n",
            "9\n",
            "6\n",
            "0\n",
            "4\n",
            "0\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "6\n",
            "3\n",
            "4\n",
            "0\n",
            "9\n",
            "7\n",
            "1\n",
            "9\n",
            "3\n",
            "8\n",
            "4\n",
            "7\n",
            "3\n",
            "0\n",
            "9\n",
            "1\n",
            "4\n",
            "5\n",
            "4\n",
            "6\n",
            "2\n",
            "0\n",
            "6\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "7\n",
            "2\n",
            "4\n",
            "7\n",
            "5\n",
            "2\n",
            "9\n",
            "4\n",
            "5\n",
            "8\n",
            "4\n",
            "2\n",
            "9\n",
            "7\n",
            "0\n",
            "0\n",
            "7\n",
            "5\n",
            "1\n",
            "1\n",
            "7\n",
            "6\n",
            "6\n",
            "6\n",
            "8\n",
            "2\n",
            "2\n",
            "7\n",
            "7\n",
            "4\n",
            "0\n",
            "2\n",
            "4\n",
            "2\n",
            "1\n",
            "8\n",
            "9\n",
            "6\n",
            "1\n",
            "0\n",
            "5\n",
            "9\n",
            "6\n",
            "9\n",
            "8\n",
            "0\n",
            "3\n",
            "0\n",
            "8\n",
            "3\n",
            "9\n",
            "6\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "5\n",
            "4\n",
            "8\n",
            "7\n",
            "4\n",
            "7\n",
            "7\n",
            "3\n",
            "9\n",
            "8\n",
            "8\n",
            "3\n",
            "1\n",
            "5\n",
            "8\n",
            "2\n",
            "7\n",
            "4\n",
            "2\n",
            "1\n",
            "5\n",
            "4\n",
            "5\n",
            "5\n",
            "8\n",
            "6\n",
            "4\n",
            "4\n",
            "4\n",
            "1\n",
            "8\n",
            "7\n",
            "5\n",
            "5\n",
            "1\n",
            "8\n",
            "9\n",
            "1\n",
            "3\n",
            "6\n",
            "3\n",
            "3\n",
            "2\n",
            "2\n",
            "6\n",
            "9\n",
            "9\n",
            "6\n",
            "5\n",
            "5\n",
            "3\n",
            "3\n",
            "8\n",
            "1\n",
            "6\n",
            "5\n",
            "6\n",
            "8\n",
            "1\n",
            "9\n",
            "7\n",
            "6\n",
            "8\n",
            "3\n",
            "7\n",
            "4\n",
            "7\n",
            "0\n",
            "9\n",
            "0\n",
            "0\n",
            "3\n",
            "2\n",
            "9\n",
            "3\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "4\n",
            "0\n",
            "1\n",
            "0\n",
            "4\n",
            "7\n",
            "9\n",
            "6\n",
            "2\n",
            "6\n",
            "2\n",
            "2\n",
            "9\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "0\n",
            "5\n",
            "6\n",
            "6\n",
            "0\n",
            "8\n",
            "0\n",
            "2\n",
            "3\n",
            "7\n",
            "9\n",
            "4\n",
            "7\n",
            "1\n",
            "9\n",
            "1\n",
            "7\n",
            "1\n",
            "4\n",
            "0\n",
            "0\n",
            "4\n",
            "1\n",
            "7\n",
            "5\n",
            "7\n",
            "1\n",
            "3\n",
            "3\n",
            "3\n",
            "1\n",
            "6\n",
            "9\n",
            "7\n",
            "4\n",
            "3\n",
            "0\n",
            "2\n",
            "5\n",
            "2\n",
            "6\n",
            "0\n",
            "8\n",
            "9\n",
            "4\n",
            "3\n",
            "5\n",
            "4\n",
            "8\n",
            "1\n",
            "5\n",
            "9\n",
            "0\n",
            "6\n",
            "4\n",
            "3\n",
            "6\n",
            "3\n",
            "3\n",
            "8\n",
            "1\n",
            "4\n",
            "7\n",
            "5\n",
            "7\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "7\n",
            "7\n",
            "9\n",
            "5\n",
            "9\n",
            "8\n",
            "9\n",
            "6\n",
            "8\n",
            "8\n",
            "2\n",
            "3\n",
            "6\n",
            "1\n",
            "2\n",
            "9\n",
            "8\n",
            "9\n",
            "5\n",
            "2\n",
            "6\n",
            "2\n",
            "4\n",
            "8\n",
            "4\n",
            "6\n",
            "5\n",
            "0\n",
            "1\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "7\n",
            "4\n",
            "2\n",
            "0\n",
            "9\n",
            "0\n",
            "1\n",
            "5\n",
            "8\n",
            "8\n",
            "0\n",
            "2\n",
            "7\n",
            "8\n",
            "4\n",
            "4\n",
            "6\n",
            "1\n",
            "0\n",
            "4\n",
            "5\n",
            "3\n",
            "9\n",
            "4\n",
            "2\n",
            "0\n",
            "5\n",
            "0\n",
            "1\n",
            "3\n",
            "2\n",
            "9\n",
            "1\n",
            "6\n",
            "0\n",
            "1\n",
            "1\n",
            "8\n",
            "0\n",
            "4\n",
            "7\n",
            "7\n",
            "6\n",
            "3\n",
            "6\n",
            "0\n",
            "7\n",
            "3\n",
            "5\n",
            "4\n",
            "2\n",
            "4\n",
            "1\n",
            "8\n",
            "3\n",
            "5\n",
            "6\n",
            "7\n",
            "0\n",
            "6\n",
            "7\n",
            "1\n",
            "2\n",
            "5\n",
            "8\n",
            "1\n",
            "9\n",
            "3\n",
            "8\n",
            "2\n",
            "8\n",
            "7\n",
            "6\n",
            "7\n",
            "1\n",
            "4\n",
            "6\n",
            "2\n",
            "9\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "8\n",
            "9\n",
            "1\n",
            "4\n",
            "0\n",
            "9\n",
            "5\n",
            "0\n",
            "8\n",
            "0\n",
            "7\n",
            "7\n",
            "1\n",
            "1\n",
            "2\n",
            "9\n",
            "3\n",
            "6\n",
            "7\n",
            "2\n",
            "3\n",
            "8\n",
            "1\n",
            "2\n",
            "9\n",
            "8\n",
            "8\n",
            "7\n",
            "1\n",
            "7\n",
            "1\n",
            "1\n",
            "0\n",
            "3\n",
            "4\n",
            "2\n",
            "6\n",
            "4\n",
            "7\n",
            "4\n",
            "2\n",
            "7\n",
            "4\n",
            "9\n",
            "1\n",
            "0\n",
            "6\n",
            "8\n",
            "5\n",
            "5\n",
            "5\n",
            "3\n",
            "5\n",
            "9\n",
            "7\n",
            "4\n",
            "8\n",
            "5\n",
            "9\n",
            "6\n",
            "9\n",
            "3\n",
            "0\n",
            "3\n",
            "8\n",
            "9\n",
            "1\n",
            "8\n",
            "1\n",
            "6\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "3\n",
            "5\n",
            "3\n",
            "2\n",
            "9\n",
            "3\n",
            "2\n",
            "1\n",
            "4\n",
            "5\n",
            "5\n",
            "2\n",
            "3\n",
            "2\n",
            "1\n",
            "3\n",
            "9\n",
            "7\n",
            "2\n",
            "1\n",
            "2\n",
            "8\n",
            "9\n",
            "1\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "7\n",
            "8\n",
            "7\n",
            "5\n",
            "0\n",
            "6\n",
            "1\n",
            "5\n",
            "7\n",
            "4\n",
            "6\n",
            "1\n",
            "2\n",
            "5\n",
            "0\n",
            "7\n",
            "9\n",
            "9\n",
            "0\n",
            "3\n",
            "8\n",
            "7\n",
            "4\n",
            "8\n",
            "1\n",
            "8\n",
            "6\n",
            "5\n",
            "9\n",
            "0\n",
            "0\n",
            "0\n",
            "3\n",
            "7\n",
            "1\n",
            "6\n",
            "4\n",
            "2\n",
            "6\n",
            "6\n",
            "0\n",
            "4\n",
            "5\n",
            "4\n",
            "1\n",
            "3\n",
            "8\n",
            "6\n",
            "3\n",
            "9\n",
            "9\n",
            "5\n",
            "9\n",
            "3\n",
            "7\n",
            "8\n",
            "5\n",
            "6\n",
            "4\n",
            "7\n",
            "6\n",
            "2\n",
            "2\n",
            "0\n",
            "9\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "8\n",
            "7\n",
            "1\n",
            "3\n",
            "2\n",
            "8\n",
            "0\n",
            "7\n",
            "5\n",
            "9\n",
            "9\n",
            "6\n",
            "0\n",
            "9\n",
            "4\n",
            "1\n",
            "3\n",
            "2\n",
            "1\n",
            "2\n",
            "3\n",
            "8\n",
            "3\n",
            "2\n",
            "6\n",
            "5\n",
            "6\n",
            "8\n",
            "2\n",
            "7\n",
            "4\n",
            "8\n",
            "1\n",
            "8\n",
            "0\n",
            "5\n",
            "3\n",
            "9\n",
            "4\n",
            "1\n",
            "9\n",
            "2\n",
            "1\n",
            "9\n",
            "6\n",
            "7\n",
            "9\n",
            "0\n",
            "4\n",
            "6\n",
            "1\n",
            "7\n",
            "3\n",
            "8\n",
            "7\n",
            "2\n",
            "9\n",
            "6\n",
            "5\n",
            "8\n",
            "3\n",
            "9\n",
            "0\n",
            "5\n",
            "7\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "9\n",
            "3\n",
            "3\n",
            "4\n",
            "4\n",
            "0\n",
            "6\n",
            "2\n",
            "5\n",
            "4\n",
            "2\n",
            "3\n",
            "4\n",
            "6\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "7\n",
            "1\n",
            "3\n",
            "7\n",
            "5\n",
            "2\n",
            "8\n",
            "0\n",
            "7\n",
            "5\n",
            "9\n",
            "9\n",
            "0\n",
            "9\n",
            "1\n",
            "1\n",
            "5\n",
            "8\n",
            "8\n",
            "6\n",
            "3\n",
            "2\n",
            "1\n",
            "8\n",
            "3\n",
            "2\n",
            "6\n",
            "5\n",
            "6\n",
            "7\n",
            "4\n",
            "1\n",
            "0\n",
            "5\n",
            "3\n",
            "1\n",
            "9\n",
            "2\n",
            "1\n",
            "9\n",
            "6\n",
            "0\n",
            "4\n",
            "6\n",
            "1\n",
            "7\n",
            "3\n",
            "8\n",
            "7\n",
            "2\n",
            "9\n",
            "6\n",
            "5\n",
            "8\n",
            "3\n",
            "5\n",
            "7\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "9\n",
            "6\n",
            "2\n",
            "5\n",
            "4\n",
            "2\n",
            "3\n",
            "4\n",
            "4\n",
            "6\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "3\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "6\n",
            "5\n",
            "0\n",
            "6\n",
            "8\n",
            "9\n",
            "4\n",
            "1\n",
            "9\n",
            "5\n",
            "3\n",
            "0\n",
            "4\n",
            "8\n",
            "9\n",
            "1\n",
            "4\n",
            "0\n",
            "5\n",
            "5\n",
            "2\n",
            "1\n",
            "5\n",
            "4\n",
            "0\n",
            "7\n",
            "6\n",
            "0\n",
            "1\n",
            "7\n",
            "0\n",
            "6\n",
            "8\n",
            "9\n",
            "9\n",
            "1\n",
            "7\n",
            "9\n",
            "8\n",
            "6\n",
            "0\n",
            "8\n",
            "1\n",
            "7\n",
            "7\n",
            "1\n",
            "3\n",
            "2\n",
            "3\n",
            "1\n",
            "4\n",
            "2\n",
            "0\n",
            "0\n",
            "7\n",
            "8\n",
            "4\n",
            "6\n",
            "4\n",
            "9\n",
            "3\n",
            "8\n",
            "4\n",
            "7\n",
            "2\n",
            "5\n",
            "6\n",
            "3\n",
            "6\n",
            "9\n",
            "6\n",
            "3\n",
            "2\n",
            "2\n",
            "4\n",
            "6\n",
            "9\n",
            "0\n",
            "2\n",
            "5\n",
            "5\n",
            "1\n",
            "3\n",
            "3\n",
            "9\n",
            "7\n",
            "8\n",
            "7\n",
            "2\n",
            "2\n",
            "5\n",
            "7\n",
            "9\n",
            "8\n",
            "2\n",
            "1\n",
            "3\n",
            "1\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "5\n",
            "1\n",
            "2\n",
            "6\n",
            "5\n",
            "3\n",
            "0\n",
            "7\n",
            "0\n",
            "4\n",
            "1\n",
            "4\n",
            "3\n",
            "6\n",
            "7\n",
            "2\n",
            "3\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "9\n",
            "6\n",
            "0\n",
            "1\n",
            "3\n",
            "0\n",
            "2\n",
            "7\n",
            "5\n",
            "7\n",
            "6\n",
            "2\n",
            "9\n",
            "1\n",
            "9\n",
            "0\n",
            "6\n",
            "0\n",
            "6\n",
            "0\n",
            "2\n",
            "0\n",
            "6\n",
            "1\n",
            "5\n",
            "8\n",
            "4\n",
            "3\n",
            "0\n",
            "1\n",
            "5\n",
            "4\n",
            "4\n",
            "8\n",
            "5\n",
            "7\n",
            "5\n",
            "7\n",
            "8\n",
            "3\n",
            "4\n",
            "8\n",
            "8\n",
            "5\n",
            "2\n",
            "9\n",
            "7\n",
            "1\n",
            "3\n",
            "8\n",
            "1\n",
            "0\n",
            "7\n",
            "5\n",
            "9\n",
            "6\n",
            "9\n",
            "4\n",
            "7\n",
            "7\n",
            "9\n",
            "4\n",
            "3\n",
            "4\n",
            "4\n",
            "3\n",
            "8\n",
            "6\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "8\n",
            "3\n",
            "9\n",
            "5\n",
            "5\n",
            "2\n",
            "6\n",
            "8\n",
            "4\n",
            "9\n",
            "1\n",
            "7\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "9\n",
            "6\n",
            "9\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "9\n",
            "5\n",
            "6\n",
            "8\n",
            "1\n",
            "2\n",
            "0\n",
            "7\n",
            "7\n",
            "5\n",
            "8\n",
            "2\n",
            "9\n",
            "8\n",
            "9\n",
            "0\n",
            "4\n",
            "6\n",
            "7\n",
            "1\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "0\n",
            "3\n",
            "6\n",
            "8\n",
            "7\n",
            "0\n",
            "4\n",
            "2\n",
            "7\n",
            "4\n",
            "7\n",
            "5\n",
            "4\n",
            "3\n",
            "4\n",
            "2\n",
            "8\n",
            "1\n",
            "5\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            "5\n",
            "6\n",
            "4\n",
            "3\n",
            "0\n",
            "0\n",
            "0\n",
            "3\n",
            "3\n",
            "5\n",
            "7\n",
            "0\n",
            "6\n",
            "4\n",
            "8\n",
            "8\n",
            "6\n",
            "3\n",
            "4\n",
            "6\n",
            "9\n",
            "9\n",
            "8\n",
            "2\n",
            "7\n",
            "7\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "2\n",
            "1\n",
            "7\n",
            "2\n",
            "5\n",
            "0\n",
            "8\n",
            "0\n",
            "2\n",
            "7\n",
            "8\n",
            "8\n",
            "3\n",
            "6\n",
            "0\n",
            "2\n",
            "7\n",
            "6\n",
            "6\n",
            "1\n",
            "2\n",
            "8\n",
            "8\n",
            "7\n",
            "7\n",
            "4\n",
            "7\n",
            "7\n",
            "3\n",
            "7\n",
            "4\n",
            "5\n",
            "4\n",
            "3\n",
            "3\n",
            "8\n",
            "4\n",
            "1\n",
            "1\n",
            "9\n",
            "7\n",
            "4\n",
            "3\n",
            "7\n",
            "3\n",
            "3\n",
            "0\n",
            "2\n",
            "5\n",
            "5\n",
            "6\n",
            "6\n",
            "3\n",
            "5\n",
            "2\n",
            "5\n",
            "9\n",
            "9\n",
            "8\n",
            "4\n",
            "1\n",
            "0\n",
            "6\n",
            "4\n",
            "9\n",
            "6\n",
            "8\n",
            "8\n",
            "5\n",
            "6\n",
            "1\n",
            "1\n",
            "9\n",
            "8\n",
            "9\n",
            "2\n",
            "3\n",
            "5\n",
            "5\n",
            "9\n",
            "4\n",
            "2\n",
            "1\n",
            "9\n",
            "3\n",
            "9\n",
            "2\n",
            "0\n",
            "6\n",
            "0\n",
            "4\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "7\n",
            "3\n",
            "0\n",
            "3\n",
            "1\n",
            "8\n",
            "7\n",
            "6\n",
            "4\n",
            "0\n",
            "2\n",
            "6\n",
            "8\n",
            "3\n",
            "2\n",
            "8\n",
            "1\n",
            "2\n",
            "0\n",
            "7\n",
            "1\n",
            "0\n",
            "4\n",
            "4\n",
            "5\n",
            "8\n",
            "0\n",
            "6\n",
            "2\n",
            "3\n",
            "1\n",
            "5\n",
            "1\n",
            "8\n",
            "5\n",
            "9\n",
            "4\n",
            "0\n",
            "7\n",
            "5\n",
            "8\n",
            "8\n",
            "3\n",
            "8\n",
            "9\n",
            "2\n",
            "6\n",
            "2\n",
            "5\n",
            "3\n",
            "1\n",
            "7\n",
            "3\n",
            "9\n",
            "1\n",
            "9\n",
            "9\n",
            "6\n",
            "0\n",
            "3\n",
            "9\n",
            "2\n",
            "8\n",
            "1\n",
            "4\n",
            "3\n",
            "5\n",
            "2\n",
            "9\n",
            "2\n",
            "5\n",
            "8\n",
            "9\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "4\n",
            "5\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "1\n",
            "0\n",
            "4\n",
            "5\n",
            "6\n",
            "6\n",
            "3\n",
            "4\n",
            "4\n",
            "2\n",
            "8\n",
            "1\n",
            "0\n",
            "6\n",
            "4\n",
            "5\n",
            "7\n",
            "2\n",
            "3\n",
            "3\n",
            "9\n",
            "2\n",
            "0\n",
            "1\n",
            "3\n",
            "3\n",
            "7\n",
            "1\n",
            "5\n",
            "2\n",
            "3\n",
            "1\n",
            "7\n",
            "8\n",
            "4\n",
            "0\n",
            "2\n",
            "4\n",
            "0\n",
            "2\n",
            "4\n",
            "7\n",
            "8\n",
            "0\n",
            "7\n",
            "0\n",
            "6\n",
            "9\n",
            "3\n",
            "2\n",
            "8\n",
            "6\n",
            "7\n",
            "5\n",
            "7\n",
            "5\n",
            "1\n",
            "0\n",
            "8\n",
            "1\n",
            "6\n",
            "7\n",
            "2\n",
            "9\n",
            "7\n",
            "9\n",
            "5\n",
            "8\n",
            "6\n",
            "2\n",
            "6\n",
            "2\n",
            "8\n",
            "1\n",
            "7\n",
            "5\n",
            "0\n",
            "1\n",
            "1\n",
            "3\n",
            "1\n",
            "4\n",
            "9\n",
            "1\n",
            "8\n",
            "6\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "7\n",
            "8\n",
            "9\n",
            "9\n",
            "8\n",
            "9\n",
            "8\n",
            "4\n",
            "1\n",
            "7\n",
            "7\n",
            "3\n",
            "3\n",
            "7\n",
            "6\n",
            "6\n",
            "6\n",
            "1\n",
            "9\n",
            "0\n",
            "1\n",
            "7\n",
            "6\n",
            "3\n",
            "2\n",
            "1\n",
            "7\n",
            "1\n",
            "3\n",
            "9\n",
            "1\n",
            "7\n",
            "6\n",
            "8\n",
            "4\n",
            "1\n",
            "4\n",
            "3\n",
            "6\n",
            "9\n",
            "6\n",
            "1\n",
            "4\n",
            "4\n",
            "7\n",
            "2\n",
            "4\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "1\n",
            "3\n",
            "5\n",
            "1\n",
            "7\n",
            "7\n",
            "2\n",
            "1\n",
            "4\n",
            "8\n",
            "3\n",
            "4\n",
            "4\n",
            "3\n",
            "9\n",
            "7\n",
            "4\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "9\n",
            "1\n",
            "6\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "8\n",
            "7\n",
            "1\n",
            "1\n",
            "4\n",
            "0\n",
            "4\n",
            "7\n",
            "3\n",
            "6\n",
            "8\n",
            "0\n",
            "3\n",
            "7\n",
            "4\n",
            "0\n",
            "6\n",
            "9\n",
            "2\n",
            "6\n",
            "5\n",
            "8\n",
            "6\n",
            "9\n",
            "0\n",
            "4\n",
            "0\n",
            "6\n",
            "1\n",
            "9\n",
            "2\n",
            "0\n",
            "9\n",
            "5\n",
            "1\n",
            "3\n",
            "7\n",
            "6\n",
            "9\n",
            "3\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "2\n",
            "1\n",
            "7\n",
            "2\n",
            "5\n",
            "0\n",
            "8\n",
            "0\n",
            "2\n",
            "7\n",
            "8\n",
            "8\n",
            "3\n",
            "0\n",
            "6\n",
            "0\n",
            "2\n",
            "7\n",
            "6\n",
            "6\n",
            "1\n",
            "2\n",
            "8\n",
            "8\n",
            "7\n",
            "7\n",
            "4\n",
            "7\n",
            "7\n",
            "3\n",
            "7\n",
            "4\n",
            "5\n",
            "4\n",
            "3\n",
            "3\n",
            "8\n",
            "4\n",
            "5\n",
            "4\n",
            "1\n",
            "1\n",
            "9\n",
            "7\n",
            "4\n",
            "3\n",
            "7\n",
            "3\n",
            "3\n",
            "0\n",
            "2\n",
            "5\n",
            "5\n",
            "6\n",
            "3\n",
            "1\n",
            "5\n",
            "2\n",
            "5\n",
            "9\n",
            "9\n",
            "8\n",
            "4\n",
            "1\n",
            "0\n",
            "6\n",
            "0\n",
            "9\n",
            "6\n",
            "8\n",
            "8\n",
            "5\n",
            "6\n",
            "1\n",
            "1\n",
            "9\n",
            "8\n",
            "9\n",
            "2\n",
            "3\n",
            "5\n",
            "5\n",
            "9\n",
            "4\n",
            "2\n",
            "1\n",
            "9\n",
            "4\n",
            "9\n",
            "1\n",
            "3\n",
            "9\n",
            "2\n",
            "0\n",
            "6\n",
            "0\n",
            "4\n",
            "0\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "3\n",
            "8\n",
            "0\n",
            "7\n",
            "1\n",
            "0\n",
            "7\n",
            "5\n",
            "5\n",
            "6\n",
            "9\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "8\n",
            "3\n",
            "4\n",
            "3\n",
            "1\n",
            "5\n",
            "0\n",
            "0\n",
            "9\n",
            "5\n",
            "3\n",
            "4\n",
            "9\n",
            "3\n",
            "7\n",
            "6\n",
            "9\n",
            "2\n",
            "4\n",
            "5\n",
            "7\n",
            "2\n",
            "6\n",
            "4\n",
            "9\n",
            "4\n",
            "9\n",
            "4\n",
            "1\n",
            "2\n",
            "2\n",
            "5\n",
            "8\n",
            "1\n",
            "3\n",
            "2\n",
            "9\n",
            "4\n",
            "3\n",
            "8\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "8\n",
            "6\n",
            "5\n",
            "1\n",
            "6\n",
            "7\n",
            "2\n",
            "1\n",
            "3\n",
            "9\n",
            "3\n",
            "8\n",
            "7\n",
            "5\n",
            "7\n",
            "0\n",
            "7\n",
            "4\n",
            "8\n",
            "8\n",
            "5\n",
            "0\n",
            "6\n",
            "6\n",
            "3\n",
            "7\n",
            "6\n",
            "9\n",
            "9\n",
            "4\n",
            "8\n",
            "4\n",
            "1\n",
            "0\n",
            "6\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "7\n",
            "4\n",
            "0\n",
            "4\n",
            "0\n",
            "1\n",
            "7\n",
            "9\n",
            "5\n",
            "1\n",
            "4\n",
            "2\n",
            "8\n",
            "9\n",
            "4\n",
            "3\n",
            "7\n",
            "8\n",
            "2\n",
            "4\n",
            "4\n",
            "3\n",
            "3\n",
            "6\n",
            "9\n",
            "9\n",
            "5\n",
            "8\n",
            "6\n",
            "7\n",
            "0\n",
            "6\n",
            "8\n",
            "2\n",
            "6\n",
            "3\n",
            "9\n",
            "3\n",
            "2\n",
            "8\n",
            "6\n",
            "1\n",
            "7\n",
            "4\n",
            "8\n",
            "8\n",
            "9\n",
            "0\n",
            "3\n",
            "3\n",
            "9\n",
            "0\n",
            "5\n",
            "2\n",
            "9\n",
            "4\n",
            "1\n",
            "0\n",
            "3\n",
            "7\n",
            "5\n",
            "8\n",
            "7\n",
            "7\n",
            "8\n",
            "2\n",
            "9\n",
            "7\n",
            "1\n",
            "2\n",
            "6\n",
            "4\n",
            "2\n",
            "5\n",
            "2\n",
            "3\n",
            "6\n",
            "6\n",
            "5\n",
            "0\n",
            "0\n",
            "2\n",
            "8\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "4\n",
            "3\n",
            "1\n",
            "6\n",
            "1\n",
            "9\n",
            "0\n",
            "1\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "4\n",
            "0\n",
            "0\n",
            "7\n",
            "2\n",
            "4\n",
            "3\n",
            "8\n",
            "6\n",
            "6\n",
            "3\n",
            "2\n",
            "6\n",
            "3\n",
            "3\n",
            "0\n",
            "1\n",
            "4\n",
            "7\n",
            "8\n",
            "0\n",
            "3\n",
            "1\n",
            "9\n",
            "0\n",
            "1\n",
            "9\n",
            "1\n",
            "2\n",
            "7\n",
            "0\n",
            "1\n",
            "3\n",
            "8\n",
            "2\n",
            "9\n",
            "2\n",
            "7\n",
            "6\n",
            "5\n",
            "5\n",
            "9\n",
            "9\n",
            "8\n",
            "2\n",
            "9\n",
            "1\n",
            "3\n",
            "2\n",
            "3\n",
            "4\n",
            "3\n",
            "1\n",
            "9\n",
            "0\n",
            "9\n",
            "3\n",
            "6\n",
            "8\n",
            "7\n",
            "0\n",
            "1\n",
            "0\n",
            "5\n",
            "8\n",
            "2\n",
            "7\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "1\n",
            "7\n",
            "4\n",
            "8\n",
            "1\n",
            "5\n",
            "6\n",
            "5\n",
            "7\n",
            "2\n",
            "8\n",
            "6\n",
            "3\n",
            "3\n",
            "8\n",
            "6\n",
            "5\n",
            "4\n",
            "0\n",
            "9\n",
            "1\n",
            "7\n",
            "2\n",
            "9\n",
            "1\n",
            "5\n",
            "1\n",
            "3\n",
            "2\n",
            "2\n",
            "3\n",
            "0\n",
            "6\n",
            "4\n",
            "3\n",
            "7\n",
            "6\n",
            "9\n",
            "0\n",
            "4\n",
            "8\n",
            "1\n",
            "4\n",
            "0\n",
            "6\n",
            "1\n",
            "2\n",
            "6\n",
            "9\n",
            "2\n",
            "2\n",
            "3\n",
            "5\n",
            "5\n",
            "1\n",
            "0\n",
            "7\n",
            "7\n",
            "9\n",
            "6\n",
            "2\n",
            "9\n",
            "4\n",
            "7\n",
            "0\n",
            "2\n",
            "3\n",
            "4\n",
            "0\n",
            "0\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "1\n",
            "3\n",
            "7\n",
            "4\n",
            "9\n",
            "8\n",
            "8\n",
            "9\n",
            "0\n",
            "9\n",
            "8\n",
            "9\n",
            "0\n",
            "2\n",
            "6\n",
            "5\n",
            "6\n",
            "7\n",
            "4\n",
            "7\n",
            "5\n",
            "4\n",
            "1\n",
            "3\n",
            "5\n",
            "3\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "1\n",
            "7\n",
            "2\n",
            "4\n",
            "1\n",
            "4\n",
            "1\n",
            "4\n",
            "9\n",
            "6\n",
            "8\n",
            "4\n",
            "5\n",
            "3\n",
            "7\n",
            "8\n",
            "4\n",
            "3\n",
            "3\n",
            "5\n",
            "6\n",
            "7\n",
            "0\n",
            "6\n",
            "1\n",
            "6\n",
            "8\n",
            "7\n",
            "0\n",
            "1\n",
            "5\n",
            "0\n",
            "8\n",
            "5\n",
            "0\n",
            "1\n",
            "5\n",
            "8\n",
            "4\n",
            "2\n",
            "3\n",
            "9\n",
            "7\n",
            "6\n",
            "9\n",
            "1\n",
            "9\n",
            "0\n",
            "6\n",
            "7\n",
            "1\n",
            "2\n",
            "3\n",
            "9\n",
            "2\n",
            "4\n",
            "5\n",
            "5\n",
            "3\n",
            "7\n",
            "5\n",
            "3\n",
            "1\n",
            "8\n",
            "2\n",
            "2\n",
            "3\n",
            "0\n",
            "2\n",
            "9\n",
            "4\n",
            "9\n",
            "7\n",
            "0\n",
            "2\n",
            "7\n",
            "4\n",
            "9\n",
            "9\n",
            "2\n",
            "5\n",
            "9\n",
            "8\n",
            "3\n",
            "8\n",
            "6\n",
            "7\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "0\n",
            "7\n",
            "2\n",
            "6\n",
            "5\n",
            "5\n",
            "3\n",
            "7\n",
            "8\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "4\n",
            "3\n",
            "8\n",
            "8\n",
            "3\n",
            "0\n",
            "1\n",
            "9\n",
            "0\n",
            "5\n",
            "4\n",
            "1\n",
            "9\n",
            "1\n",
            "2\n",
            "7\n",
            "0\n",
            "1\n",
            "3\n",
            "8\n",
            "2\n",
            "9\n",
            "2\n",
            "7\n",
            "4\n",
            "2\n",
            "6\n",
            "5\n",
            "5\n",
            "9\n",
            "9\n",
            "1\n",
            "1\n",
            "5\n",
            "7\n",
            "6\n",
            "8\n",
            "2\n",
            "9\n",
            "4\n",
            "3\n",
            "1\n",
            "9\n",
            "0\n",
            "9\n",
            "3\n",
            "6\n",
            "8\n",
            "7\n",
            "0\n",
            "1\n",
            "0\n",
            "5\n",
            "8\n",
            "2\n",
            "7\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "3\n",
            "9\n",
            "9\n",
            "8\n",
            "5\n",
            "3\n",
            "7\n",
            "0\n",
            "7\n",
            "7\n",
            "5\n",
            "7\n",
            "9\n",
            "9\n",
            "4\n",
            "7\n",
            "0\n",
            "3\n",
            "4\n",
            "1\n",
            "5\n",
            "8\n",
            "1\n",
            "4\n",
            "8\n",
            "4\n",
            "1\n",
            "8\n",
            "6\n",
            "6\n",
            "4\n",
            "6\n",
            "0\n",
            "5\n",
            "5\n",
            "3\n",
            "3\n",
            "5\n",
            "7\n",
            "2\n",
            "5\n",
            "9\n",
            "6\n",
            "9\n",
            "2\n",
            "6\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "8\n",
            "3\n",
            "8\n",
            "3\n",
            "0\n",
            "8\n",
            "7\n",
            "4\n",
            "9\n",
            "5\n",
            "0\n",
            "9\n",
            "7\n",
            "0\n",
            "0\n",
            "4\n",
            "6\n",
            "0\n",
            "9\n",
            "1\n",
            "6\n",
            "2\n",
            "7\n",
            "6\n",
            "8\n",
            "3\n",
            "5\n",
            "2\n",
            "1\n",
            "8\n",
            "3\n",
            "8\n",
            "6\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "7\n",
            "6\n",
            "4\n",
            "7\n",
            "6\n",
            "2\n",
            "3\n",
            "4\n",
            "8\n",
            "7\n",
            "8\n",
            "6\n",
            "9\n",
            "8\n",
            "3\n",
            "2\n",
            "2\n",
            "8\n",
            "4\n",
            "8\n",
            "5\n",
            "6\n",
            "5\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "9\n",
            "6\n",
            "8\n",
            "2\n",
            "1\n",
            "0\n",
            "6\n",
            "5\n",
            "2\n",
            "9\n",
            "7\n",
            "5\n",
            "3\n",
            "9\n",
            "3\n",
            "7\n",
            "1\n",
            "8\n",
            "3\n",
            "8\n",
            "1\n",
            "9\n",
            "5\n",
            "5\n",
            "0\n",
            "1\n",
            "1\n",
            "9\n",
            "8\n",
            "2\n",
            "6\n",
            "0\n",
            "4\n",
            "5\n",
            "0\n",
            "3\n",
            "1\n",
            "8\n",
            "6\n",
            "7\n",
            "5\n",
            "9\n",
            "9\n",
            "3\n",
            "0\n",
            "3\n",
            "1\n",
            "4\n",
            "4\n",
            "0\n",
            "4\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "9\n",
            "7\n",
            "0\n",
            "9\n",
            "0\n",
            "1\n",
            "5\n",
            "8\n",
            "8\n",
            "0\n",
            "9\n",
            "3\n",
            "2\n",
            "7\n",
            "8\n",
            "4\n",
            "6\n",
            "1\n",
            "0\n",
            "4\n",
            "9\n",
            "4\n",
            "2\n",
            "0\n",
            "5\n",
            "0\n",
            "1\n",
            "6\n",
            "9\n",
            "3\n",
            "2\n",
            "9\n",
            "1\n",
            "6\n",
            "0\n",
            "1\n",
            "1\n",
            "8\n",
            "7\n",
            "7\n",
            "6\n",
            "3\n",
            "6\n",
            "0\n",
            "7\n",
            "2\n",
            "4\n",
            "1\n",
            "7\n",
            "0\n",
            "6\n",
            "7\n",
            "1\n",
            "2\n",
            "5\n",
            "8\n",
            "1\n",
            "8\n",
            "2\n",
            "8\n",
            "7\n",
            "6\n",
            "8\n",
            "7\n",
            "1\n",
            "6\n",
            "2\n",
            "9\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "9\n",
            "5\n",
            "7\n",
            "0\n",
            "3\n",
            "1\n",
            "6\n",
            "8\n",
            "4\n",
            "1\n",
            "5\n",
            "6\n",
            "4\n",
            "2\n",
            "7\n",
            "8\n",
            "1\n",
            "3\n",
            "4\n",
            "3\n",
            "4\n",
            "7\n",
            "2\n",
            "0\n",
            "5\n",
            "0\n",
            "1\n",
            "9\n",
            "2\n",
            "3\n",
            "2\n",
            "3\n",
            "5\n",
            "5\n",
            "7\n",
            "8\n",
            "4\n",
            "9\n",
            "9\n",
            "7\n",
            "1\n",
            "1\n",
            "9\n",
            "0\n",
            "7\n",
            "8\n",
            "3\n",
            "4\n",
            "8\n",
            "6\n",
            "3\n",
            "8\n",
            "0\n",
            "9\n",
            "6\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "6\n",
            "2\n",
            "3\n",
            "8\n",
            "9\n",
            "0\n",
            "7\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "5\n",
            "2\n",
            "8\n",
            "5\n",
            "4\n",
            "6\n",
            "6\n",
            "6\n",
            "7\n",
            "9\n",
            "1\n",
            "8\n",
            "2\n",
            "1\n",
            "5\n",
            "3\n",
            "4\n",
            "7\n",
            "9\n",
            "4\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "9\n",
            "0\n",
            "1\n",
            "3\n",
            "1\n",
            "5\n",
            "1\n",
            "2\n",
            "4\n",
            "9\n",
            "2\n",
            "4\n",
            "6\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "9\n",
            "2\n",
            "6\n",
            "6\n",
            "8\n",
            "7\n",
            "4\n",
            "2\n",
            "9\n",
            "7\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "3\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "6\n",
            "5\n",
            "9\n",
            "7\n",
            "0\n",
            "2\n",
            "3\n",
            "4\n",
            "3\n",
            "8\n",
            "5\n",
            "1\n",
            "5\n",
            "2\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "3\n",
            "2\n",
            "6\n",
            "5\n",
            "3\n",
            "0\n",
            "7\n",
            "2\n",
            "7\n",
            "4\n",
            "6\n",
            "4\n",
            "0\n",
            "5\n",
            "9\n",
            "9\n",
            "8\n",
            "9\n",
            "5\n",
            "3\n",
            "1\n",
            "7\n",
            "4\n",
            "7\n",
            "6\n",
            "5\n",
            "4\n",
            "0\n",
            "0\n",
            "6\n",
            "6\n",
            "2\n",
            "0\n",
            "6\n",
            "3\n",
            "7\n",
            "7\n",
            "4\n",
            "4\n",
            "3\n",
            "9\n",
            "2\n",
            "8\n",
            "9\n",
            "6\n",
            "0\n",
            "9\n",
            "5\n",
            "3\n",
            "8\n",
            "8\n",
            "7\n",
            "1\n",
            "4\n",
            "0\n",
            "4\n",
            "8\n",
            "5\n",
            "2\n",
            "3\n",
            "9\n",
            "0\n",
            "1\n",
            "9\n",
            "1\n",
            "5\n",
            "1\n",
            "7\n",
            "4\n",
            "8\n",
            "6\n",
            "2\n",
            "1\n",
            "6\n",
            "8\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "1\n",
            "4\n",
            "5\n",
            "3\n",
            "3\n",
            "0\n",
            "9\n",
            "5\n",
            "4\n",
            "3\n",
            "0\n",
            "8\n",
            "4\n",
            "6\n",
            "7\n",
            "0\n",
            "7\n",
            "7\n",
            "1\n",
            "6\n",
            "9\n",
            "1\n",
            "3\n",
            "6\n",
            "2\n",
            "3\n",
            "8\n",
            "2\n",
            "3\n",
            "8\n",
            "9\n",
            "5\n",
            "8\n",
            "8\n",
            "7\n",
            "1\n",
            "7\n",
            "1\n",
            "1\n",
            "0\n",
            "3\n",
            "4\n",
            "2\n",
            "6\n",
            "4\n",
            "7\n",
            "4\n",
            "2\n",
            "7\n",
            "4\n",
            "2\n",
            "9\n",
            "2\n",
            "7\n",
            "9\n",
            "2\n",
            "1\n",
            "6\n",
            "6\n",
            "5\n",
            "3\n",
            "4\n",
            "8\n",
            "5\n",
            "7\n",
            "6\n",
            "9\n",
            "0\n",
            "6\n",
            "3\n",
            "0\n",
            "8\n",
            "1\n",
            "6\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "2\n",
            "5\n",
            "1\n",
            "6\n",
            "4\n",
            "3\n",
            "9\n",
            "9\n",
            "0\n",
            "9\n",
            "7\n",
            "1\n",
            "6\n",
            "4\n",
            "3\n",
            "6\n",
            "2\n",
            "0\n",
            "9\n",
            "8\n",
            "6\n",
            "5\n",
            "7\n",
            "0\n",
            "0\n",
            "1\n",
            "7\n",
            "4\n",
            "3\n",
            "2\n",
            "4\n",
            "1\n",
            "3\n",
            "7\n",
            "6\n",
            "4\n",
            "7\n",
            "7\n",
            "7\n",
            "9\n",
            "8\n",
            "4\n",
            "3\n",
            "8\n",
            "2\n",
            "8\n",
            "3\n",
            "5\n",
            "8\n",
            "0\n",
            "5\n",
            "4\n",
            "7\n",
            "1\n",
            "3\n",
            "1\n",
            "7\n",
            "9\n",
            "6\n",
            "2\n",
            "0\n",
            "9\n",
            "1\n",
            "7\n",
            "3\n",
            "3\n",
            "9\n",
            "1\n",
            "6\n",
            "4\n",
            "3\n",
            "9\n",
            "8\n",
            "2\n",
            "1\n",
            "8\n",
            "6\n",
            "4\n",
            "1\n",
            "5\n",
            "5\n",
            "6\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "6\n",
            "9\n",
            "7\n",
            "0\n",
            "2\n",
            "3\n",
            "4\n",
            "3\n",
            "8\n",
            "5\n",
            "1\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "3\n",
            "2\n",
            "0\n",
            "7\n",
            "2\n",
            "6\n",
            "4\n",
            "0\n",
            "5\n",
            "9\n",
            "9\n",
            "8\n",
            "9\n",
            "5\n",
            "3\n",
            "1\n",
            "7\n",
            "4\n",
            "7\n",
            "0\n",
            "0\n",
            "6\n",
            "6\n",
            "6\n",
            "3\n",
            "7\n",
            "4\n",
            "2\n",
            "8\n",
            "9\n",
            "8\n",
            "7\n",
            "1\n",
            "9\n",
            "0\n",
            "4\n",
            "8\n",
            "5\n",
            "2\n",
            "3\n",
            "9\n",
            "0\n",
            "1\n",
            "9\n",
            "1\n",
            "5\n",
            "1\n",
            "7\n",
            "6\n",
            "1\n",
            "2\n",
            "1\n",
            "6\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "1\n",
            "0\n",
            "4\n",
            "5\n",
            "6\n",
            "6\n",
            "3\n",
            "4\n",
            "4\n",
            "2\n",
            "8\n",
            "1\n",
            "0\n",
            "6\n",
            "4\n",
            "9\n",
            "7\n",
            "2\n",
            "9\n",
            "2\n",
            "0\n",
            "9\n",
            "3\n",
            "3\n",
            "9\n",
            "1\n",
            "5\n",
            "2\n",
            "3\n",
            "1\n",
            "6\n",
            "7\n",
            "3\n",
            "7\n",
            "8\n",
            "4\n",
            "0\n",
            "2\n",
            "4\n",
            "0\n",
            "2\n",
            "4\n",
            "7\n",
            "8\n",
            "0\n",
            "7\n",
            "0\n",
            "6\n",
            "9\n",
            "3\n",
            "2\n",
            "4\n",
            "8\n",
            "6\n",
            "0\n",
            "5\n",
            "7\n",
            "5\n",
            "1\n",
            "0\n",
            "8\n",
            "1\n",
            "6\n",
            "7\n",
            "2\n",
            "9\n",
            "7\n",
            "9\n",
            "5\n",
            "6\n",
            "5\n",
            "2\n",
            "6\n",
            "2\n",
            "8\n",
            "1\n",
            "7\n",
            "5\n",
            "5\n",
            "7\n",
            "3\n",
            "5\n",
            "0\n",
            "1\n",
            "1\n",
            "3\n",
            "8\n",
            "4\n",
            "9\n",
            "4\n",
            "5\n",
            "1\n",
            "8\n",
            "6\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "3\n",
            "5\n",
            "3\n",
            "2\n",
            "9\n",
            "3\n",
            "2\n",
            "1\n",
            "4\n",
            "5\n",
            "5\n",
            "2\n",
            "3\n",
            "2\n",
            "1\n",
            "3\n",
            "9\n",
            "7\n",
            "2\n",
            "1\n",
            "2\n",
            "8\n",
            "9\n",
            "1\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "1\n",
            "0\n",
            "0\n",
            "6\n",
            "7\n",
            "7\n",
            "8\n",
            "7\n",
            "5\n",
            "0\n",
            "6\n",
            "1\n",
            "5\n",
            "7\n",
            "4\n",
            "6\n",
            "1\n",
            "2\n",
            "5\n",
            "0\n",
            "7\n",
            "9\n",
            "9\n",
            "0\n",
            "3\n",
            "4\n",
            "4\n",
            "8\n",
            "4\n",
            "1\n",
            "8\n",
            "6\n",
            "5\n",
            "9\n",
            "0\n",
            "0\n",
            "0\n",
            "3\n",
            "7\n",
            "1\n",
            "6\n",
            "4\n",
            "6\n",
            "0\n",
            "4\n",
            "5\n",
            "4\n",
            "1\n",
            "3\n",
            "8\n",
            "6\n",
            "3\n",
            "9\n",
            "9\n",
            "5\n",
            "9\n",
            "3\n",
            "7\n",
            "8\n",
            "5\n",
            "6\n",
            "4\n",
            "7\n",
            "6\n",
            "2\n",
            "2\n",
            "0\n",
            "9\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "6\n",
            "4\n",
            "2\n",
            "6\n",
            "4\n",
            "7\n",
            "5\n",
            "5\n",
            "4\n",
            "7\n",
            "2\n",
            "9\n",
            "3\n",
            "9\n",
            "3\n",
            "8\n",
            "2\n",
            "0\n",
            "9\n",
            "5\n",
            "6\n",
            "0\n",
            "1\n",
            "0\n",
            "6\n",
            "5\n",
            "3\n",
            "5\n",
            "3\n",
            "8\n",
            "0\n",
            "0\n",
            "3\n",
            "4\n",
            "1\n",
            "5\n",
            "3\n",
            "0\n",
            "8\n",
            "3\n",
            "0\n",
            "6\n",
            "2\n",
            "7\n",
            "8\n",
            "1\n",
            "7\n",
            "1\n",
            "3\n",
            "8\n",
            "5\n",
            "4\n",
            "2\n",
            "0\n",
            "9\n",
            "7\n",
            "6\n",
            "7\n",
            "4\n",
            "1\n",
            "6\n",
            "2\n",
            "6\n",
            "7\n",
            "1\n",
            "9\n",
            "8\n",
            "0\n",
            "6\n",
            "9\n",
            "4\n",
            "9\n",
            "9\n",
            "6\n",
            "2\n",
            "3\n",
            "7\n",
            "1\n",
            "9\n",
            "2\n",
            "2\n",
            "5\n",
            "3\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "7\n",
            "8\n",
            "9\n",
            "8\n",
            "9\n",
            "2\n",
            "6\n",
            "1\n",
            "3\n",
            "5\n",
            "4\n",
            "8\n",
            "2\n",
            "6\n",
            "4\n",
            "3\n",
            "4\n",
            "5\n",
            "9\n",
            "2\n",
            "0\n",
            "3\n",
            "9\n",
            "4\n",
            "9\n",
            "7\n",
            "3\n",
            "8\n",
            "7\n",
            "4\n",
            "4\n",
            "9\n",
            "8\n",
            "5\n",
            "8\n",
            "2\n",
            "6\n",
            "6\n",
            "2\n",
            "3\n",
            "1\n",
            "3\n",
            "2\n",
            "7\n",
            "3\n",
            "1\n",
            "9\n",
            "0\n",
            "1\n",
            "1\n",
            "3\n",
            "5\n",
            "0\n",
            "7\n",
            "8\n",
            "1\n",
            "5\n",
            "1\n",
            "4\n",
            "6\n",
            "0\n",
            "0\n",
            "4\n",
            "9\n",
            "1\n",
            "6\n",
            "6\n",
            "9\n",
            "0\n",
            "7\n",
            "6\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "2\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "8\n",
            "6\n",
            "3\n",
            "9\n",
            "7\n",
            "1\n",
            "9\n",
            "3\n",
            "9\n",
            "6\n",
            "1\n",
            "7\n",
            "2\n",
            "4\n",
            "4\n",
            "5\n",
            "7\n",
            "0\n",
            "0\n",
            "1\n",
            "6\n",
            "6\n",
            "8\n",
            "2\n",
            "7\n",
            "7\n",
            "2\n",
            "4\n",
            "2\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "6\n",
            "9\n",
            "8\n",
            "3\n",
            "9\n",
            "6\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "1\n",
            "6\n",
            "8\n",
            "9\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "4\n",
            "4\n",
            "3\n",
            "7\n",
            "4\n",
            "4\n",
            "4\n",
            "0\n",
            "3\n",
            "8\n",
            "7\n",
            "5\n",
            "8\n",
            "2\n",
            "1\n",
            "7\n",
            "5\n",
            "3\n",
            "8\n",
            "5\n",
            "2\n",
            "5\n",
            "1\n",
            "1\n",
            "6\n",
            "2\n",
            "1\n",
            "3\n",
            "8\n",
            "6\n",
            "4\n",
            "2\n",
            "6\n",
            "2\n",
            "5\n",
            "5\n",
            "0\n",
            "2\n",
            "8\n",
            "0\n",
            "6\n",
            "8\n",
            "1\n",
            "7\n",
            "9\n",
            "1\n",
            "9\n",
            "2\n",
            "6\n",
            "7\n",
            "6\n",
            "6\n",
            "8\n",
            "7\n",
            "4\n",
            "9\n",
            "2\n",
            "1\n",
            "3\n",
            "3\n",
            "0\n",
            "5\n",
            "5\n",
            "8\n",
            "0\n",
            "3\n",
            "7\n",
            "9\n",
            "7\n",
            "0\n",
            "2\n",
            "7\n",
            "9\n",
            "1\n",
            "7\n",
            "8\n",
            "0\n",
            "3\n",
            "5\n",
            "3\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "6\n",
            "4\n",
            "2\n",
            "6\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "2\n",
            "9\n",
            "3\n",
            "9\n",
            "3\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "4\n",
            "2\n",
            "6\n",
            "3\n",
            "5\n",
            "3\n",
            "0\n",
            "3\n",
            "4\n",
            "1\n",
            "5\n",
            "3\n",
            "0\n",
            "8\n",
            "3\n",
            "0\n",
            "6\n",
            "1\n",
            "7\n",
            "8\n",
            "0\n",
            "9\n",
            "2\n",
            "6\n",
            "7\n",
            "1\n",
            "9\n",
            "6\n",
            "9\n",
            "4\n",
            "9\n",
            "9\n",
            "6\n",
            "7\n",
            "1\n",
            "2\n",
            "5\n",
            "3\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "7\n",
            "5\n",
            "5\n",
            "1\n",
            "9\n",
            "9\n",
            "7\n",
            "1\n",
            "0\n",
            "0\n",
            "5\n",
            "9\n",
            "7\n",
            "1\n",
            "7\n",
            "2\n",
            "2\n",
            "3\n",
            "6\n",
            "8\n",
            "3\n",
            "2\n",
            "0\n",
            "0\n",
            "6\n",
            "1\n",
            "7\n",
            "5\n",
            "8\n",
            "6\n",
            "2\n",
            "9\n",
            "4\n",
            "8\n",
            "8\n",
            "7\n",
            "1\n",
            "0\n",
            "8\n",
            "7\n",
            "7\n",
            "5\n",
            "8\n",
            "5\n",
            "3\n",
            "4\n",
            "6\n",
            "1\n",
            "1\n",
            "5\n",
            "5\n",
            "0\n",
            "7\n",
            "2\n",
            "3\n",
            "6\n",
            "4\n",
            "1\n",
            "2\n",
            "4\n",
            "1\n",
            "5\n",
            "4\n",
            "2\n",
            "0\n",
            "4\n",
            "8\n",
            "6\n",
            "1\n",
            "9\n",
            "0\n",
            "2\n",
            "5\n",
            "6\n",
            "9\n",
            "3\n",
            "6\n",
            "3\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "1\n",
            "0\n",
            "9\n",
            "5\n",
            "7\n",
            "5\n",
            "1\n",
            "8\n",
            "6\n",
            "9\n",
            "0\n",
            "4\n",
            "1\n",
            "9\n",
            "3\n",
            "8\n",
            "4\n",
            "4\n",
            "7\n",
            "0\n",
            "1\n",
            "9\n",
            "2\n",
            "8\n",
            "7\n",
            "8\n",
            "2\n",
            "5\n",
            "9\n",
            "6\n",
            "0\n",
            "6\n",
            "5\n",
            "5\n",
            "3\n",
            "3\n",
            "3\n",
            "9\n",
            "8\n",
            "1\n",
            "1\n",
            "0\n",
            "6\n",
            "1\n",
            "0\n",
            "0\n",
            "6\n",
            "2\n",
            "1\n",
            "1\n",
            "3\n",
            "2\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "8\n",
            "4\n",
            "6\n",
            "0\n",
            "2\n",
            "0\n",
            "7\n",
            "0\n",
            "3\n",
            "6\n",
            "8\n",
            "7\n",
            "1\n",
            "5\n",
            "9\n",
            "9\n",
            "3\n",
            "7\n",
            "2\n",
            "4\n",
            "9\n",
            "4\n",
            "3\n",
            "6\n",
            "2\n",
            "2\n",
            "5\n",
            "3\n",
            "2\n",
            "5\n",
            "5\n",
            "9\n",
            "4\n",
            "1\n",
            "7\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "7\n",
            "5\n",
            "3\n",
            "4\n",
            "4\n",
            "0\n",
            "0\n",
            "6\n",
            "8\n",
            "6\n",
            "6\n",
            "5\n",
            "7\n",
            "2\n",
            "3\n",
            "4\n",
            "4\n",
            "9\n",
            "1\n",
            "4\n",
            "0\n",
            "7\n",
            "9\n",
            "5\n",
            "7\n",
            "2\n",
            "3\n",
            "1\n",
            "4\n",
            "4\n",
            "0\n",
            "9\n",
            "9\n",
            "6\n",
            "1\n",
            "8\n",
            "3\n",
            "3\n",
            "7\n",
            "3\n",
            "9\n",
            "8\n",
            "8\n",
            "4\n",
            "7\n",
            "7\n",
            "6\n",
            "2\n",
            "1\n",
            "9\n",
            "8\n",
            "7\n",
            "8\n",
            "8\n",
            "7\n",
            "2\n",
            "2\n",
            "3\n",
            "9\n",
            "3\n",
            "3\n",
            "5\n",
            "5\n",
            "0\n",
            "7\n",
            "4\n",
            "5\n",
            "6\n",
            "5\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "2\n",
            "8\n",
            "2\n",
            "6\n",
            "1\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "8\n",
            "0\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "7\n",
            "7\n",
            "4\n",
            "7\n",
            "1\n",
            "9\n",
            "1\n",
            "7\n",
            "1\n",
            "4\n",
            "0\n",
            "0\n",
            "1\n",
            "7\n",
            "5\n",
            "7\n",
            "1\n",
            "3\n",
            "3\n",
            "3\n",
            "1\n",
            "6\n",
            "9\n",
            "7\n",
            "1\n",
            "3\n",
            "0\n",
            "2\n",
            "6\n",
            "0\n",
            "8\n",
            "9\n",
            "4\n",
            "3\n",
            "5\n",
            "4\n",
            "8\n",
            "1\n",
            "5\n",
            "9\n",
            "0\n",
            "6\n",
            "1\n",
            "3\n",
            "8\n",
            "1\n",
            "4\n",
            "7\n",
            "5\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "7\n",
            "8\n",
            "7\n",
            "6\n",
            "8\n",
            "8\n",
            "2\n",
            "3\n",
            "6\n",
            "1\n",
            "2\n",
            "9\n",
            "5\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "6\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "7\n",
            "4\n",
            "6\n",
            "1\n",
            "4\n",
            "0\n",
            "9\n",
            "9\n",
            "3\n",
            "7\n",
            "8\n",
            "4\n",
            "7\n",
            "5\n",
            "8\n",
            "6\n",
            "3\n",
            "2\n",
            "2\n",
            "0\n",
            "6\n",
            "8\n",
            "6\n",
            "0\n",
            "3\n",
            "8\n",
            "1\n",
            "0\n",
            "3\n",
            "0\n",
            "4\n",
            "7\n",
            "4\n",
            "9\n",
            "2\n",
            "9\n",
            "0\n",
            "7\n",
            "1\n",
            "7\n",
            "1\n",
            "6\n",
            "6\n",
            "5\n",
            "6\n",
            "2\n",
            "8\n",
            "7\n",
            "6\n",
            "4\n",
            "9\n",
            "9\n",
            "5\n",
            "3\n",
            "7\n",
            "4\n",
            "3\n",
            "0\n",
            "9\n",
            "6\n",
            "6\n",
            "1\n",
            "1\n",
            "3\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "8\n",
            "3\n",
            "9\n",
            "5\n",
            "5\n",
            "2\n",
            "6\n",
            "8\n",
            "4\n",
            "1\n",
            "7\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "6\n",
            "9\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "7\n",
            "7\n",
            "5\n",
            "8\n",
            "2\n",
            "9\n",
            "8\n",
            "6\n",
            "7\n",
            "3\n",
            "4\n",
            "6\n",
            "8\n",
            "7\n",
            "0\n",
            "4\n",
            "2\n",
            "7\n",
            "7\n",
            "5\n",
            "4\n",
            "3\n",
            "4\n",
            "2\n",
            "8\n",
            "1\n",
            "5\n",
            "1\n",
            "0\n",
            "2\n",
            "3\n",
            "3\n",
            "5\n",
            "7\n",
            "0\n",
            "6\n",
            "8\n",
            "0\n",
            "3\n",
            "9\n",
            "9\n",
            "8\n",
            "2\n",
            "7\n",
            "7\n",
            "1\n",
            "0\n",
            "1\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "7\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "7\n",
            "8\n",
            "6\n",
            "4\n",
            "1\n",
            "9\n",
            "3\n",
            "8\n",
            "4\n",
            "4\n",
            "7\n",
            "0\n",
            "1\n",
            "9\n",
            "2\n",
            "8\n",
            "7\n",
            "8\n",
            "2\n",
            "6\n",
            "0\n",
            "6\n",
            "5\n",
            "3\n",
            "3\n",
            "3\n",
            "9\n",
            "1\n",
            "4\n",
            "0\n",
            "6\n",
            "1\n",
            "0\n",
            "0\n",
            "6\n",
            "2\n",
            "1\n",
            "1\n",
            "7\n",
            "7\n",
            "8\n",
            "4\n",
            "6\n",
            "0\n",
            "7\n",
            "0\n",
            "3\n",
            "6\n",
            "8\n",
            "7\n",
            "1\n",
            "5\n",
            "2\n",
            "4\n",
            "9\n",
            "4\n",
            "3\n",
            "6\n",
            "4\n",
            "1\n",
            "7\n",
            "2\n",
            "6\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}